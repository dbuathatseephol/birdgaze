{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "330ba56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4n/qw3nb3kj7v98xpjkjv1_54pm0000gn/T/ipykernel_8270/3059630660.py:279: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = agg.groupby(\"condition\", group_keys=False).apply(ranker).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ TOP PDF: /Users/daisybuathatseephol/Documents/three_json_output/plots/TOP3_second_image_fix_heat.pdf\n",
      "✅ BOTTOM PDF: /Users/daisybuathatseephol/Documents/three_json_output/plots/BOTTOM3_second_image_fix_heat.pdf\n"
     ]
    }
   ],
   "source": [
    "# file: scripts/export_second_image_fixations_heatmaps.py\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import re\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Iterable, List, Optional, Sequence, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from PIL import Image\n",
    "\n",
    "try:\n",
    "    from scipy.ndimage import gaussian_filter  # type: ignore\n",
    "except Exception:  # pragma: no cover\n",
    "    gaussian_filter = None\n",
    "\n",
    "\n",
    "CONDITIONS: Tuple[str, ...] = (\"full\", \"central\", \"peripheral\")\n",
    "IMAGE_EXTS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\")\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PairKey:\n",
    "    a: str\n",
    "    b: str\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        return f\"{self.a}__{self.b}\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrialRow:\n",
    "    condition: str\n",
    "    pair: PairKey\n",
    "    first_image: str\n",
    "    second_image: str\n",
    "    correct: Optional[bool]\n",
    "    raw: Dict[str, Any]\n",
    "\n",
    "\n",
    "def _normalize_image_name(name: str) -> str:\n",
    "    s = str(name).strip().lower()\n",
    "    s = re.sub(r\"\\.(jpg|jpeg|png|bmp|tif|tiff)$\", \"\", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "def _clean_condition(x: Any) -> Optional[str]:\n",
    "    if x is None:\n",
    "        return None\n",
    "    s = str(x).strip().lower()\n",
    "    return s if s in CONDITIONS else None\n",
    "\n",
    "\n",
    "def _as_bool(x: Any) -> Optional[bool]:\n",
    "    if x is None:\n",
    "        return None\n",
    "    if isinstance(x, bool):\n",
    "        return x\n",
    "    if isinstance(x, (int, np.integer)):\n",
    "        if x in (0, 1):\n",
    "            return bool(x)\n",
    "        return None\n",
    "    if isinstance(x, str):\n",
    "        v = x.strip().lower()\n",
    "        if v in (\"true\", \"t\", \"yes\", \"y\", \"correct\", \"right\", \"1\"):\n",
    "            return True\n",
    "        if v in (\"false\", \"f\", \"no\", \"n\", \"incorrect\", \"wrong\", \"0\"):\n",
    "            return False\n",
    "    return None\n",
    "\n",
    "\n",
    "def _normalize_answer(x: Any) -> Optional[str]:\n",
    "    if x is None:\n",
    "        return None\n",
    "    s = str(x).strip().lower()\n",
    "    return s or None\n",
    "\n",
    "\n",
    "def _detect_correct(item: Dict[str, Any]) -> Optional[bool]:\n",
    "    for k in (\"acc\", \"correct\", \"is_correct\", \"response_correct\", \"trial_correct\", \"accuracy\"):\n",
    "        if k in item:\n",
    "            b = _as_bool(item.get(k))\n",
    "            if b is not None:\n",
    "                return b\n",
    "\n",
    "    subj = _normalize_answer(item.get(\"subj_answer\"))\n",
    "    corr = _normalize_answer(item.get(\"correct_response\"))\n",
    "    if subj is not None and corr is not None:\n",
    "        return subj == corr\n",
    "    return None\n",
    "\n",
    "\n",
    "def _find_testing_json(root: Path) -> Path:\n",
    "    hits = list(root.rglob(\"testing.json\"))\n",
    "    if not hits:\n",
    "        raise FileNotFoundError(f\"❌ testing.json not found under: {root}\")\n",
    "    hits.sort(key=lambda p: (len(p.parts), str(p)))\n",
    "    return hits[0]\n",
    "\n",
    "\n",
    "def _find_image_file(root: Path, image_name: str) -> Optional[Path]:\n",
    "    base = _normalize_image_name(image_name)\n",
    "    candidates: List[Path] = []\n",
    "    for p in root.rglob(\"*\"):\n",
    "        if not p.is_file():\n",
    "            continue\n",
    "        if p.suffix.lower() not in IMAGE_EXTS:\n",
    "            continue\n",
    "        if _normalize_image_name(p.name) == base or _normalize_image_name(p.stem) == base:\n",
    "            candidates.append(p)\n",
    "    if not candidates:\n",
    "        return None\n",
    "    candidates.sort(key=lambda p: (len(p.parts), str(p)))\n",
    "    return candidates[0]\n",
    "\n",
    "\n",
    "def _iter_trials(data: Sequence[Dict[str, Any]]) -> Iterable[TrialRow]:\n",
    "    for item in data:\n",
    "        cond = _clean_condition(item.get(\"viewing_condition\") or item.get(\"condition\"))\n",
    "        if cond is None:\n",
    "            continue\n",
    "\n",
    "        first = item.get(\"first_image\")\n",
    "        second = item.get(\"second_image\")\n",
    "        if not first or not second:\n",
    "            continue\n",
    "\n",
    "        first_s = str(first).strip()\n",
    "        second_s = str(second).strip()\n",
    "\n",
    "        a = _normalize_image_name(first_s)\n",
    "        b = _normalize_image_name(second_s)\n",
    "        pair = PairKey(*sorted((a, b)))\n",
    "\n",
    "        yield TrialRow(\n",
    "            condition=cond,\n",
    "            pair=pair,\n",
    "            first_image=first_s,\n",
    "            second_image=second_s,\n",
    "            correct=_detect_correct(item),\n",
    "            raw=item,\n",
    "        )\n",
    "\n",
    "\n",
    "def _extract_fixations(item: Dict[str, Any]) -> np.ndarray:\n",
    "    xs = item.get(\"fix_x\")\n",
    "    ys = item.get(\"fix_y\")\n",
    "    if not isinstance(xs, (list, tuple)) or not isinstance(ys, (list, tuple)):\n",
    "        return np.zeros((0, 2), dtype=float)\n",
    "    if len(xs) != len(ys) or len(xs) == 0:\n",
    "        return np.zeros((0, 2), dtype=float)\n",
    "    try:\n",
    "        arr = np.column_stack([np.asarray(xs, dtype=float), np.asarray(ys, dtype=float)])\n",
    "        arr = arr[np.isfinite(arr).all(axis=1)]\n",
    "        return arr\n",
    "    except Exception:\n",
    "        return np.zeros((0, 2), dtype=float)\n",
    "\n",
    "\n",
    "def _screen_dims(item: Dict[str, Any], default: Tuple[int, int]) -> Tuple[int, int]:\n",
    "    for kw, kh in (\n",
    "        (\"screen_width\", \"screen_height\"),\n",
    "        (\"window_width\", \"window_height\"),\n",
    "        (\"display_width\", \"display_height\"),\n",
    "        (\"screenW\", \"screenH\"),\n",
    "    ):\n",
    "        if kw in item and kh in item:\n",
    "            try:\n",
    "                w = int(float(item[kw]))\n",
    "                h = int(float(item[kh]))\n",
    "                if w > 0 and h > 0:\n",
    "                    return w, h\n",
    "            except Exception:\n",
    "                pass\n",
    "    return default\n",
    "\n",
    "\n",
    "def _image_box_extent(screen_w: int, screen_h: int, half_box: int) -> Tuple[int, int, int, int]:\n",
    "    \"\"\"\n",
    "    Matches your snippet:\n",
    "    l, t, r, b = (screen_w//2 - half_box, screen_h//2 - half_box,\n",
    "                  screen_w//2 + half_box, screen_h//2 + half_box)\n",
    "    \"\"\"\n",
    "    l = screen_w // 2 - half_box\n",
    "    t = screen_h // 2 - half_box\n",
    "    r = screen_w // 2 + half_box\n",
    "    b = screen_h // 2 + half_box\n",
    "    return l, t, r, b\n",
    "\n",
    "\n",
    "def _load_image_resized(path: Path, size_px: int) -> np.ndarray:\n",
    "    img = Image.open(path).convert(\"L\")\n",
    "    img = img.resize((size_px, size_px), resample=Image.BICUBIC)\n",
    "    return np.asarray(img)\n",
    "\n",
    "\n",
    "def _fdm_in_box(\n",
    "    pts: np.ndarray,\n",
    "    l: int,\n",
    "    t: int,\n",
    "    r: int,\n",
    "    b: int,\n",
    "    size_px: int,\n",
    "    sigma: float,\n",
    ") -> np.ndarray:\n",
    "    if len(pts) == 0:\n",
    "        return np.zeros((size_px, size_px), dtype=float)\n",
    "\n",
    "    in_box = (pts[:, 0] >= l) & (pts[:, 0] <= r) & (pts[:, 1] >= t) & (pts[:, 1] <= b)\n",
    "    p = pts[in_box]\n",
    "    if len(p) == 0:\n",
    "        return np.zeros((size_px, size_px), dtype=float)\n",
    "\n",
    "    x = (p[:, 0] - l) / max(1e-9, (r - l)) * (size_px - 1)\n",
    "    y = (p[:, 1] - t) / max(1e-9, (b - t)) * (size_px - 1)\n",
    "    x = np.clip(x, 0, size_px - 1)\n",
    "    y = np.clip(y, 0, size_px - 1)\n",
    "\n",
    "    heat, _, _ = np.histogram2d(y, x, bins=[size_px, size_px], range=[[0, size_px], [0, size_px]])\n",
    "    heat = heat.astype(float)\n",
    "\n",
    "    if gaussian_filter is not None:\n",
    "        heat = gaussian_filter(heat, sigma=sigma)\n",
    "    else:\n",
    "        k = int(max(3, math.ceil(sigma * 3)) * 2 + 1)\n",
    "        ax = np.arange(k) - k // 2\n",
    "        kernel = np.exp(-(ax**2) / (2 * sigma**2))\n",
    "        kernel /= kernel.sum()\n",
    "        heat = np.apply_along_axis(lambda m: np.convolve(m, kernel, mode=\"same\"), axis=0, arr=heat)\n",
    "        heat = np.apply_along_axis(lambda m: np.convolve(m, kernel, mode=\"same\"), axis=1, arr=heat)\n",
    "\n",
    "    s = heat.sum()\n",
    "    if s > 0:\n",
    "        heat /= s  # density (matches your PDF-ish colorbar scale)\n",
    "    return heat\n",
    "\n",
    "\n",
    "def _aggregate_accuracy(trials: Sequence[TrialRow]) -> pd.DataFrame:\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "    for t in trials:\n",
    "        if t.correct is None:\n",
    "            continue\n",
    "        rows.append(\n",
    "            {\"condition\": t.condition, \"pair\": t.pair.as_str, \"correct\": int(bool(t.correct))}\n",
    "        )\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        raise ValueError(\"❌ No trials with correctness detected (acc / subj_answer vs correct_response).\")\n",
    "\n",
    "    return (\n",
    "        df.groupby([\"condition\", \"pair\"], as_index=False)\n",
    "        .agg(N=(\"correct\", \"size\"), right=(\"correct\", \"sum\"))\n",
    "        .assign(wrong=lambda x: x[\"N\"] - x[\"right\"])\n",
    "        .assign(acc=lambda x: x[\"right\"] / x[\"N\"])\n",
    "    )\n",
    "\n",
    "\n",
    "def _rank_pairs_within_condition(agg: pd.DataFrame) -> pd.DataFrame:\n",
    "    def ranker(group: pd.DataFrame) -> pd.DataFrame:\n",
    "        g_inc = group.sort_values([\"acc\", \"pair\"], ascending=[True, True]).reset_index(drop=True)\n",
    "        g_inc[\"rank_most_incorrect\"] = np.arange(1, len(g_inc) + 1)\n",
    "\n",
    "        g_cor = group.sort_values([\"acc\", \"pair\"], ascending=[False, True]).reset_index(drop=True)\n",
    "        g_cor[\"rank_most_correct\"] = np.arange(1, len(g_cor) + 1)\n",
    "\n",
    "        merged = g_inc.merge(g_cor[[\"pair\", \"rank_most_correct\"]], on=\"pair\", how=\"left\")\n",
    "        merged[\"n_pairs_in_condition\"] = len(group)\n",
    "        return merged\n",
    "\n",
    "    out = agg.groupby(\"condition\", group_keys=False).apply(ranker).reset_index(drop=True)\n",
    "    out[\"condition\"] = pd.Categorical(out[\"condition\"], categories=list(CONDITIONS), ordered=True)\n",
    "    return out\n",
    "\n",
    "\n",
    "def _collect_trials(all_trials: Sequence[TrialRow], condition: str, pair_str: str) -> List[TrialRow]:\n",
    "    return [t for t in all_trials if t.condition == condition and t.pair.as_str == pair_str]\n",
    "\n",
    "\n",
    "def _select_top_k(agg_ranked: pd.DataFrame, k: int) -> Dict[str, pd.DataFrame]:\n",
    "    out: Dict[str, pd.DataFrame] = {}\n",
    "    for cond in CONDITIONS:\n",
    "        sub = agg_ranked[agg_ranked[\"condition\"] == cond].copy()\n",
    "        out[cond] = sub.sort_values([\"acc\", \"pair\"], ascending=[False, True]).head(k).reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "\n",
    "def _select_bottom_k(agg_ranked: pd.DataFrame, k: int) -> Dict[str, pd.DataFrame]:\n",
    "    out: Dict[str, pd.DataFrame] = {}\n",
    "    for cond in CONDITIONS:\n",
    "        sub = agg_ranked[agg_ranked[\"condition\"] == cond].copy()\n",
    "        out[cond] = sub.sort_values([\"acc\", \"pair\"], ascending=[True, True]).head(k).reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "\n",
    "def _plot_fixations_only(\n",
    "    ax: plt.Axes,\n",
    "    img_arr: np.ndarray,\n",
    "    pts: np.ndarray,\n",
    "    screen_w: int,\n",
    "    screen_h: int,\n",
    "    extent: Tuple[int, int, int, int],  # (l, t, r, b)\n",
    "    title: str,\n",
    ") -> None:\n",
    "    l, t, r, b = extent\n",
    "    ax.imshow(img_arr, cmap=\"gray\", origin=\"upper\", extent=(l, r, b, t))\n",
    "\n",
    "    if len(pts) > 0:\n",
    "        ax.scatter(\n",
    "            pts[:, 0],\n",
    "            pts[:, 1],\n",
    "            s=30,\n",
    "            facecolors=(1.0, 0.42, 0.42, 0.50),  # like #FF6B6B, but RGBA\n",
    "            edgecolors=(1.0, 1.0, 1.0, 0.80),\n",
    "            linewidths=0.8,\n",
    "        )\n",
    "\n",
    "    ax.set_xlim(0, screen_w)\n",
    "    ax.set_ylim(screen_h, 0)\n",
    "    ax.set_xlabel(\"x (screen px)\")\n",
    "    ax.set_ylabel(\"y (screen px)\")\n",
    "    ax.set_title(title, fontsize=10)\n",
    "    ax.grid(False)\n",
    "\n",
    "\n",
    "def _plot_heatmap_only(\n",
    "    ax: plt.Axes,\n",
    "    img_arr: np.ndarray,\n",
    "    heat: np.ndarray,\n",
    "    screen_w: int,\n",
    "    screen_h: int,\n",
    "    extent: Tuple[int, int, int, int],  # (l, t, r, b)\n",
    "    title: str,\n",
    "    cmap: str,\n",
    "    alpha: float,\n",
    "    vmax_mode: str,\n",
    ") -> Any:\n",
    "    l, t, r, b = extent\n",
    "    ax.imshow(img_arr, cmap=\"gray\", origin=\"upper\", extent=(l, r, b, t))\n",
    "\n",
    "    if vmax_mode == \"p99\":\n",
    "        vmax = float(np.quantile(heat, 0.99)) if heat.max() > 0 else 1.0\n",
    "    else:\n",
    "        vmax = float(heat.max()) if heat.max() > 0 else 1.0\n",
    "\n",
    "    hm = ax.imshow(\n",
    "        heat,\n",
    "        origin=\"upper\",\n",
    "        extent=(l, r, b, t),\n",
    "        cmap=cmap,\n",
    "        alpha=alpha,\n",
    "        vmin=0.0,\n",
    "        vmax=vmax,\n",
    "    )\n",
    "\n",
    "    ax.set_xlim(0, screen_w)\n",
    "    ax.set_ylim(screen_h, 0)\n",
    "    ax.set_xlabel(\"x (screen px)\")\n",
    "    ax.set_ylabel(\"y (screen px)\")\n",
    "    ax.set_title(title, fontsize=10)\n",
    "    ax.grid(False)\n",
    "    return hm\n",
    "\n",
    "\n",
    "def export_pdfs(\n",
    "    root_path: str,\n",
    "    output_dir: str,\n",
    "    k: int = 3,\n",
    "    half_box: int = 310,\n",
    "    screen_default: Tuple[int, int] = (1000, 800),\n",
    "    sigma: float = 18.0,\n",
    "    heatmap_alpha: float = 0.70,\n",
    "    heatmap_cmap: str = \"turbo\",\n",
    "    vmax_mode: str = \"p99\",\n",
    ") -> Tuple[Path, Path]:\n",
    "    root = Path(root_path).expanduser().resolve()\n",
    "    out_dir = Path(output_dir).expanduser().resolve()\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    json_path = _find_testing_json(root)\n",
    "    data = json.loads(json_path.read_text(encoding=\"utf-8\"))\n",
    "    if not isinstance(data, list):\n",
    "        raise ValueError(\"❌ testing.json must be a list of objects.\")\n",
    "\n",
    "    all_trials = list(_iter_trials(data))\n",
    "    agg = _aggregate_accuracy(all_trials)\n",
    "    agg_ranked = _rank_pairs_within_condition(agg)\n",
    "\n",
    "    agg_ranked.to_csv(out_dir / \"accuracy_by_pair_condition.csv\", index=False)\n",
    "\n",
    "    top = _select_top_k(agg_ranked, k=k)\n",
    "    bottom = _select_bottom_k(agg_ranked, k=k)\n",
    "\n",
    "    top_pdf = out_dir / f\"TOP{k}_second_image_fix_heat.pdf\"\n",
    "    bottom_pdf = out_dir / f\"BOTTOM{k}_second_image_fix_heat.pdf\"\n",
    "\n",
    "    def _page_for(rank_i: int, group: str, selection: Dict[str, pd.DataFrame], pdf: PdfPages) -> None:\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 10), constrained_layout=True)\n",
    "        last_hm = None\n",
    "\n",
    "        for col, cond in enumerate(CONDITIONS):\n",
    "            ax_fix = axes[0, col]\n",
    "            ax_hm = axes[1, col]\n",
    "\n",
    "            sub = selection[cond]\n",
    "            if rank_i >= len(sub):\n",
    "                ax_fix.axis(\"off\")\n",
    "                ax_hm.axis(\"off\")\n",
    "                continue\n",
    "\n",
    "            row = sub.iloc[rank_i]\n",
    "            pair_str = str(row[\"pair\"])\n",
    "            trials = _collect_trials(all_trials, cond, pair_str)\n",
    "            if not trials:\n",
    "                ax_fix.axis(\"off\")\n",
    "                ax_hm.axis(\"off\")\n",
    "                continue\n",
    "\n",
    "            # second image only\n",
    "            img_path = _find_image_file(root, trials[0].second_image)\n",
    "            if img_path is None:\n",
    "                ax_fix.set_title(f\"{cond.upper()} • missing second image\", fontsize=10)\n",
    "                ax_hm.set_title(f\"{cond.upper()} • missing second image\", fontsize=10)\n",
    "                ax_fix.axis(\"off\")\n",
    "                ax_hm.axis(\"off\")\n",
    "                continue\n",
    "\n",
    "            sw, sh = screen_default\n",
    "            for t in trials[:3]:\n",
    "                sw, sh = _screen_dims(t.raw, (sw, sh))\n",
    "\n",
    "            l, ttop, r, b = _image_box_extent(sw, sh, half_box=half_box)\n",
    "            box_size = int(half_box * 2)\n",
    "\n",
    "            img_arr = _load_image_resized(img_path, size_px=box_size)\n",
    "\n",
    "            pts_list = [_extract_fixations(t.raw) for t in trials]\n",
    "            pts = np.vstack([p for p in pts_list if len(p) > 0]) if any(len(p) > 0 for p in pts_list) else np.zeros((0, 2))\n",
    "\n",
    "            heat = _fdm_in_box(pts, l=l, t=ttop, r=r, b=b, size_px=box_size, sigma=sigma)\n",
    "\n",
    "            acc = float(row[\"acc\"])\n",
    "            right = int(row[\"right\"])\n",
    "            wrong = int(row[\"wrong\"])\n",
    "            N = int(row[\"N\"])\n",
    "            n_pairs = int(row[\"n_pairs_in_condition\"])\n",
    "            pair_rank = int(row[\"rank_most_correct\"]) if group == \"TOP\" else int(row[\"rank_most_incorrect\"])\n",
    "\n",
    "            title_base = f\"Testing • {cond.upper()} • Acc: {acc*100:.1f}% • Pair {pair_rank}/{n_pairs} • N={N}\"\n",
    "            title_fix = title_base + f\"\\nSecond Image • Fixations • right={right} wrong={wrong} • Fix={len(pts)}\"\n",
    "            title_hm = title_base + f\"\\nSecond Image • Density Heatmap • right={right} wrong={wrong} • Fix={len(pts)}\"\n",
    "\n",
    "            _plot_fixations_only(\n",
    "                ax=ax_fix,\n",
    "                img_arr=img_arr,\n",
    "                pts=pts,\n",
    "                screen_w=sw,\n",
    "                screen_h=sh,\n",
    "                extent=(l, ttop, r, b),\n",
    "                title=title_fix,\n",
    "            )\n",
    "            last_hm = _plot_heatmap_only(\n",
    "                ax=ax_hm,\n",
    "                img_arr=img_arr,\n",
    "                heat=heat,\n",
    "                screen_w=sw,\n",
    "                screen_h=sh,\n",
    "                extent=(l, ttop, r, b),\n",
    "                title=title_hm,\n",
    "                cmap=heatmap_cmap,\n",
    "                alpha=heatmap_alpha,\n",
    "                vmax_mode=vmax_mode,\n",
    "            )\n",
    "\n",
    "        fig.suptitle(\n",
    "            f\"Testing Phase • {group} {rank_i+1}/{k} • Second Image Only • Fixations + Heatmap\",\n",
    "            fontsize=14,\n",
    "        )\n",
    "\n",
    "        if last_hm is not None:\n",
    "            cbar = fig.colorbar(last_hm, ax=axes.ravel().tolist(), shrink=0.85, pad=0.02)\n",
    "            cbar.set_label(\"Fixation Density\", rotation=90)\n",
    "\n",
    "        pdf.savefig(fig)\n",
    "        plt.close(fig)\n",
    "\n",
    "    with PdfPages(top_pdf) as pdf:\n",
    "        for i in range(k):\n",
    "            _page_for(i, \"TOP\", top, pdf)\n",
    "\n",
    "    with PdfPages(bottom_pdf) as pdf:\n",
    "        for i in range(k):\n",
    "            _page_for(i, \"BOTTOM\", bottom, pdf)\n",
    "\n",
    "    return top_pdf, bottom_pdf\n",
    "\n",
    "\n",
    "def _running_in_notebook(argv: List[str]) -> bool:\n",
    "    return \"-f\" in argv or \"ipykernel\" in argv[0].lower()\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Export PDFs (TOPk and BOTTOMk), each page has 6 panels: 3 conditions × (fixations row + heatmap row), second image only.\"\n",
    "    )\n",
    "    parser.add_argument(\"--root\", default=\".\", help=\"Folder to search for testing.json and images.\")\n",
    "    parser.add_argument(\"--out\", default=\"plots\", help=\"Output directory.\")\n",
    "    parser.add_argument(\"--k\", type=int, default=3)\n",
    "    parser.add_argument(\"--half-box\", type=int, default=310, help=\"Half side of centered image box in screen px.\")\n",
    "    parser.add_argument(\"--screen-w\", type=int, default=1000)\n",
    "    parser.add_argument(\"--screen-h\", type=int, default=800)\n",
    "    parser.add_argument(\"--sigma\", type=float, default=18.0)\n",
    "    parser.add_argument(\"--heatmap-alpha\", type=float, default=0.70)\n",
    "    parser.add_argument(\"--heatmap-cmap\", default=\"turbo\")\n",
    "    parser.add_argument(\"--vmax-mode\", default=\"p99\", choices=[\"p99\", \"max\"])\n",
    "\n",
    "    argv = sys.argv[1:]\n",
    "    if _running_in_notebook(sys.argv):\n",
    "        args = parser.parse_args([])  # ignore Jupyter argv\n",
    "    else:\n",
    "        args, _unknown = parser.parse_known_args(argv)\n",
    "\n",
    "    top_pdf, bottom_pdf = export_pdfs(\n",
    "        root_path=args.root,\n",
    "        output_dir=args.out,\n",
    "        k=int(args.k),\n",
    "        half_box=int(args.half_box),\n",
    "        screen_default=(int(args.screen_w), int(args.screen_h)),\n",
    "        sigma=float(args.sigma),\n",
    "        heatmap_alpha=float(args.heatmap_alpha),\n",
    "        heatmap_cmap=str(args.heatmap_cmap),\n",
    "        vmax_mode=str(args.vmax_mode),\n",
    "    )\n",
    "    print(f\"✅ TOP PDF: {top_pdf}\")\n",
    "    print(f\"✅ BOTTOM PDF: {bottom_pdf}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d83ba2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4n/qw3nb3kj7v98xpjkjv1_54pm0000gn/T/ipykernel_8270/806046250.py:270: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = agg.groupby(\"condition\", group_keys=False).apply(ranker).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ TOP PDF: /Users/daisybuathatseephol/Documents/three_json_output/plots/TOP3_second_image_overlay.pdf\n",
      "✅ BOTTOM PDF: /Users/daisybuathatseephol/Documents/three_json_output/plots/BOTTOM3_second_image_overlay.pdf\n"
     ]
    }
   ],
   "source": [
    "# file: scripts/export_second_image_overlay_top_bottom_k.py\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import re\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Iterable, List, Optional, Sequence, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from PIL import Image\n",
    "\n",
    "try:\n",
    "    from scipy.ndimage import gaussian_filter  # type: ignore\n",
    "except Exception:  # pragma: no cover\n",
    "    gaussian_filter = None\n",
    "\n",
    "\n",
    "CONDITIONS: Tuple[str, ...] = (\"full\", \"central\", \"peripheral\")\n",
    "IMAGE_EXTS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\")\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PairKey:\n",
    "    a: str\n",
    "    b: str\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        return f\"{self.a}__{self.b}\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrialRow:\n",
    "    condition: str\n",
    "    pair: PairKey\n",
    "    first_image: str\n",
    "    second_image: str\n",
    "    correct: Optional[bool]\n",
    "    raw: Dict[str, Any]\n",
    "\n",
    "\n",
    "def _normalize_image_name(name: str) -> str:\n",
    "    s = str(name).strip().lower()\n",
    "    s = re.sub(r\"\\.(jpg|jpeg|png|bmp|tif|tiff)$\", \"\", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "def _clean_condition(x: Any) -> Optional[str]:\n",
    "    if x is None:\n",
    "        return None\n",
    "    s = str(x).strip().lower()\n",
    "    return s if s in CONDITIONS else None\n",
    "\n",
    "\n",
    "def _as_bool(x: Any) -> Optional[bool]:\n",
    "    if x is None:\n",
    "        return None\n",
    "    if isinstance(x, bool):\n",
    "        return x\n",
    "    if isinstance(x, (int, np.integer)) and x in (0, 1):\n",
    "        return bool(x)\n",
    "    if isinstance(x, str):\n",
    "        v = x.strip().lower()\n",
    "        if v in (\"true\", \"t\", \"yes\", \"y\", \"correct\", \"right\", \"1\"):\n",
    "            return True\n",
    "        if v in (\"false\", \"f\", \"no\", \"n\", \"incorrect\", \"wrong\", \"0\"):\n",
    "            return False\n",
    "    return None\n",
    "\n",
    "\n",
    "def _normalize_answer(x: Any) -> Optional[str]:\n",
    "    if x is None:\n",
    "        return None\n",
    "    s = str(x).strip().lower()\n",
    "    return s or None\n",
    "\n",
    "\n",
    "def _detect_correct(item: Dict[str, Any]) -> Optional[bool]:\n",
    "    for k in (\"acc\", \"correct\", \"is_correct\", \"response_correct\", \"trial_correct\", \"accuracy\"):\n",
    "        if k in item:\n",
    "            b = _as_bool(item.get(k))\n",
    "            if b is not None:\n",
    "                return b\n",
    "\n",
    "    subj = _normalize_answer(item.get(\"subj_answer\"))\n",
    "    corr = _normalize_answer(item.get(\"correct_response\"))\n",
    "    if subj is not None and corr is not None:\n",
    "        return subj == corr\n",
    "    return None\n",
    "\n",
    "\n",
    "def _find_testing_json(root: Path) -> Path:\n",
    "    hits = list(root.rglob(\"testing.json\"))\n",
    "    if not hits:\n",
    "        raise FileNotFoundError(f\"❌ testing.json not found under: {root}\")\n",
    "    hits.sort(key=lambda p: (len(p.parts), str(p)))\n",
    "    return hits[0]\n",
    "\n",
    "\n",
    "def _find_image_file(root: Path, image_name: str) -> Optional[Path]:\n",
    "    base = _normalize_image_name(image_name)\n",
    "    candidates: List[Path] = []\n",
    "    for p in root.rglob(\"*\"):\n",
    "        if not p.is_file():\n",
    "            continue\n",
    "        if p.suffix.lower() not in IMAGE_EXTS:\n",
    "            continue\n",
    "        if _normalize_image_name(p.name) == base or _normalize_image_name(p.stem) == base:\n",
    "            candidates.append(p)\n",
    "    if not candidates:\n",
    "        return None\n",
    "    candidates.sort(key=lambda p: (len(p.parts), str(p)))\n",
    "    return candidates[0]\n",
    "\n",
    "\n",
    "def _iter_trials(data: Sequence[Dict[str, Any]]) -> Iterable[TrialRow]:\n",
    "    for item in data:\n",
    "        cond = _clean_condition(item.get(\"viewing_condition\") or item.get(\"condition\"))\n",
    "        if cond is None:\n",
    "            continue\n",
    "\n",
    "        first = item.get(\"first_image\")\n",
    "        second = item.get(\"second_image\")\n",
    "        if not first or not second:\n",
    "            continue\n",
    "\n",
    "        first_s = str(first).strip()\n",
    "        second_s = str(second).strip()\n",
    "\n",
    "        a = _normalize_image_name(first_s)\n",
    "        b = _normalize_image_name(second_s)\n",
    "        pair = PairKey(*sorted((a, b)))\n",
    "\n",
    "        yield TrialRow(\n",
    "            condition=cond,\n",
    "            pair=pair,\n",
    "            first_image=first_s,\n",
    "            second_image=second_s,\n",
    "            correct=_detect_correct(item),\n",
    "            raw=item,\n",
    "        )\n",
    "\n",
    "\n",
    "def _extract_fixations(item: Dict[str, Any]) -> np.ndarray:\n",
    "    xs = item.get(\"fix_x\")\n",
    "    ys = item.get(\"fix_y\")\n",
    "    if not isinstance(xs, (list, tuple)) or not isinstance(ys, (list, tuple)):\n",
    "        return np.zeros((0, 2), dtype=float)\n",
    "    if len(xs) != len(ys) or len(xs) == 0:\n",
    "        return np.zeros((0, 2), dtype=float)\n",
    "    try:\n",
    "        arr = np.column_stack([np.asarray(xs, dtype=float), np.asarray(ys, dtype=float)])\n",
    "        arr = arr[np.isfinite(arr).all(axis=1)]\n",
    "        return arr\n",
    "    except Exception:\n",
    "        return np.zeros((0, 2), dtype=float)\n",
    "\n",
    "\n",
    "def _screen_dims(item: Dict[str, Any], default: Tuple[int, int]) -> Tuple[int, int]:\n",
    "    for kw, kh in (\n",
    "        (\"screen_width\", \"screen_height\"),\n",
    "        (\"window_width\", \"window_height\"),\n",
    "        (\"display_width\", \"display_height\"),\n",
    "        (\"screenW\", \"screenH\"),\n",
    "    ):\n",
    "        if kw in item and kh in item:\n",
    "            try:\n",
    "                w = int(float(item[kw]))\n",
    "                h = int(float(item[kh]))\n",
    "                if w > 0 and h > 0:\n",
    "                    return w, h\n",
    "            except Exception:\n",
    "                pass\n",
    "    return default\n",
    "\n",
    "\n",
    "def _image_box_extent(screen_w: int, screen_h: int, half_box: int) -> Tuple[int, int, int, int]:\n",
    "    l = screen_w // 2 - half_box\n",
    "    t = screen_h // 2 - half_box\n",
    "    r = screen_w // 2 + half_box\n",
    "    b = screen_h // 2 + half_box\n",
    "    return l, t, r, b\n",
    "\n",
    "\n",
    "def _load_image_resized(path: Path, size_px: int) -> np.ndarray:\n",
    "    img = Image.open(path).convert(\"L\")\n",
    "    img = img.resize((size_px, size_px), resample=Image.BICUBIC)\n",
    "    return np.asarray(img)\n",
    "\n",
    "\n",
    "def _fdm_in_box(\n",
    "    pts: np.ndarray,\n",
    "    l: int,\n",
    "    t: int,\n",
    "    r: int,\n",
    "    b: int,\n",
    "    size_px: int,\n",
    "    sigma: float,\n",
    ") -> np.ndarray:\n",
    "    if len(pts) == 0:\n",
    "        return np.zeros((size_px, size_px), dtype=float)\n",
    "\n",
    "    in_box = (pts[:, 0] >= l) & (pts[:, 0] <= r) & (pts[:, 1] >= t) & (pts[:, 1] <= b)\n",
    "    p = pts[in_box]\n",
    "    if len(p) == 0:\n",
    "        return np.zeros((size_px, size_px), dtype=float)\n",
    "\n",
    "    x = (p[:, 0] - l) / max(1e-9, (r - l)) * (size_px - 1)\n",
    "    y = (p[:, 1] - t) / max(1e-9, (b - t)) * (size_px - 1)\n",
    "    x = np.clip(x, 0, size_px - 1)\n",
    "    y = np.clip(y, 0, size_px - 1)\n",
    "\n",
    "    heat, _, _ = np.histogram2d(y, x, bins=[size_px, size_px], range=[[0, size_px], [0, size_px]])\n",
    "    heat = heat.astype(float)\n",
    "\n",
    "    if gaussian_filter is not None:\n",
    "        heat = gaussian_filter(heat, sigma=sigma)\n",
    "    else:\n",
    "        k = int(max(3, math.ceil(sigma * 3)) * 2 + 1)\n",
    "        ax = np.arange(k) - k // 2\n",
    "        kernel = np.exp(-(ax**2) / (2 * sigma**2))\n",
    "        kernel /= kernel.sum()\n",
    "        heat = np.apply_along_axis(lambda m: np.convolve(m, kernel, mode=\"same\"), axis=0, arr=heat)\n",
    "        heat = np.apply_along_axis(lambda m: np.convolve(m, kernel, mode=\"same\"), axis=1, arr=heat)\n",
    "\n",
    "    s = heat.sum()\n",
    "    if s > 0:\n",
    "        heat /= s  # density\n",
    "    return heat\n",
    "\n",
    "\n",
    "def _aggregate_accuracy(trials: Sequence[TrialRow]) -> pd.DataFrame:\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "    for t in trials:\n",
    "        if t.correct is None:\n",
    "            continue\n",
    "        rows.append({\"condition\": t.condition, \"pair\": t.pair.as_str, \"correct\": int(bool(t.correct))})\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        raise ValueError(\"❌ No correctness detected (acc / subj_answer vs correct_response).\")\n",
    "\n",
    "    return (\n",
    "        df.groupby([\"condition\", \"pair\"], as_index=False)\n",
    "        .agg(N=(\"correct\", \"size\"), right=(\"correct\", \"sum\"))\n",
    "        .assign(wrong=lambda x: x[\"N\"] - x[\"right\"])\n",
    "        .assign(acc=lambda x: x[\"right\"] / x[\"N\"])\n",
    "    )\n",
    "\n",
    "\n",
    "def _rank_pairs_within_condition(agg: pd.DataFrame) -> pd.DataFrame:\n",
    "    def ranker(group: pd.DataFrame) -> pd.DataFrame:\n",
    "        g_inc = group.sort_values([\"acc\", \"pair\"], ascending=[True, True]).reset_index(drop=True)\n",
    "        g_inc[\"rank_most_incorrect\"] = np.arange(1, len(g_inc) + 1)\n",
    "\n",
    "        g_cor = group.sort_values([\"acc\", \"pair\"], ascending=[False, True]).reset_index(drop=True)\n",
    "        g_cor[\"rank_most_correct\"] = np.arange(1, len(g_cor) + 1)\n",
    "\n",
    "        merged = g_inc.merge(g_cor[[\"pair\", \"rank_most_correct\"]], on=\"pair\", how=\"left\")\n",
    "        merged[\"n_pairs_in_condition\"] = len(group)\n",
    "        return merged\n",
    "\n",
    "    out = agg.groupby(\"condition\", group_keys=False).apply(ranker).reset_index(drop=True)\n",
    "    out[\"condition\"] = pd.Categorical(out[\"condition\"], categories=list(CONDITIONS), ordered=True)\n",
    "    return out\n",
    "\n",
    "\n",
    "def _collect_trials(all_trials: Sequence[TrialRow], condition: str, pair_str: str) -> List[TrialRow]:\n",
    "    return [t for t in all_trials if t.condition == condition and t.pair.as_str == pair_str]\n",
    "\n",
    "\n",
    "def _select_top_k(agg_ranked: pd.DataFrame, k: int) -> Dict[str, pd.DataFrame]:\n",
    "    out: Dict[str, pd.DataFrame] = {}\n",
    "    for cond in CONDITIONS:\n",
    "        sub = agg_ranked[agg_ranked[\"condition\"] == cond].copy()\n",
    "        out[cond] = sub.sort_values([\"acc\", \"pair\"], ascending=[False, True]).head(k).reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "\n",
    "def _select_bottom_k(agg_ranked: pd.DataFrame, k: int) -> Dict[str, pd.DataFrame]:\n",
    "    out: Dict[str, pd.DataFrame] = {}\n",
    "    for cond in CONDITIONS:\n",
    "        sub = agg_ranked[agg_ranked[\"condition\"] == cond].copy()\n",
    "        out[cond] = sub.sort_values([\"acc\", \"pair\"], ascending=[True, True]).head(k).reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "\n",
    "def _plot_overlay(\n",
    "    ax: plt.Axes,\n",
    "    img_arr: np.ndarray,\n",
    "    pts: np.ndarray,\n",
    "    heat: np.ndarray,\n",
    "    screen_w: int,\n",
    "    screen_h: int,\n",
    "    extent_ltrb: Tuple[int, int, int, int],  # (l,t,r,b)\n",
    "    title: str,\n",
    "    heatmap_cmap: str,\n",
    "    heatmap_alpha: float,\n",
    "    vmax_mode: str,\n",
    ") -> Any:\n",
    "    l, t, r, b = extent_ltrb\n",
    "\n",
    "    ax.imshow(img_arr, cmap=\"gray\", origin=\"upper\", extent=(l, r, b, t))\n",
    "\n",
    "    vmax = float(np.quantile(heat, 0.99)) if (vmax_mode == \"p99\" and heat.max() > 0) else float(heat.max() or 1.0)\n",
    "    hm = ax.imshow(\n",
    "        heat,\n",
    "        origin=\"upper\",\n",
    "        extent=(l, r, b, t),\n",
    "        cmap=heatmap_cmap,\n",
    "        alpha=heatmap_alpha,\n",
    "        vmin=0.0,\n",
    "        vmax=vmax,\n",
    "    )\n",
    "\n",
    "    if len(pts) > 0:\n",
    "        ax.scatter(\n",
    "            pts[:, 0],\n",
    "            pts[:, 1],\n",
    "            s=30,\n",
    "            facecolors=(1.0, 0.42, 0.42, 0.50),\n",
    "            edgecolors=(1.0, 1.0, 1.0, 0.80),\n",
    "            linewidths=0.8,\n",
    "        )\n",
    "\n",
    "    ax.set_xlim(0, screen_w)\n",
    "    ax.set_ylim(screen_h, 0)\n",
    "    ax.set_xlabel(\"x (screen px)\")\n",
    "    ax.set_ylabel(\"y (screen px)\")\n",
    "    ax.set_title(title, fontsize=10)\n",
    "    ax.grid(False)\n",
    "    return hm\n",
    "\n",
    "\n",
    "def export_pdfs(\n",
    "    root_path: str,\n",
    "    output_dir: str,\n",
    "    k: int = 3,\n",
    "    half_box: int = 310,\n",
    "    screen_default: Tuple[int, int] = (1000, 800),\n",
    "    sigma: float = 18.0,\n",
    "    heatmap_alpha: float = 0.70,\n",
    "    heatmap_cmap: str = \"turbo\",\n",
    "    vmax_mode: str = \"p99\",\n",
    "    single_pdf: bool = False,\n",
    ") -> Tuple[Path, Optional[Path]]:\n",
    "    root = Path(root_path).expanduser().resolve()\n",
    "    out_dir = Path(output_dir).expanduser().resolve()\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    json_path = _find_testing_json(root)\n",
    "    data = json.loads(json_path.read_text(encoding=\"utf-8\"))\n",
    "    if not isinstance(data, list):\n",
    "        raise ValueError(\"❌ testing.json must be a list of objects.\")\n",
    "\n",
    "    all_trials = list(_iter_trials(data))\n",
    "    agg = _aggregate_accuracy(all_trials)\n",
    "    agg_ranked = _rank_pairs_within_condition(agg)\n",
    "    agg_ranked.to_csv(out_dir / \"accuracy_by_pair_condition.csv\", index=False)\n",
    "\n",
    "    top = _select_top_k(agg_ranked, k=k)\n",
    "    bottom = _select_bottom_k(agg_ranked, k=k)\n",
    "\n",
    "    top_pdf = out_dir / f\"TOP{k}_second_image_overlay.pdf\"\n",
    "    bottom_pdf = out_dir / f\"BOTTOM{k}_second_image_overlay.pdf\"\n",
    "    combined_pdf = out_dir / f\"TOP{k}_BOTTOM{k}_second_image_overlay.pdf\"\n",
    "\n",
    "    def _write_group(pdf: PdfPages, group_name: str, selection: Dict[str, pd.DataFrame]) -> None:\n",
    "        for rank_i in range(k):\n",
    "            fig, axes = plt.subplots(1, 3, figsize=(18, 6), constrained_layout=True)\n",
    "            last_hm = None\n",
    "\n",
    "            for col, cond in enumerate(CONDITIONS):\n",
    "                ax = axes[col]\n",
    "                sub = selection[cond]\n",
    "                if rank_i >= len(sub):\n",
    "                    ax.axis(\"off\")\n",
    "                    continue\n",
    "\n",
    "                row = sub.iloc[rank_i]\n",
    "                pair_str = str(row[\"pair\"])\n",
    "                trials = _collect_trials(all_trials, cond, pair_str)\n",
    "                if not trials:\n",
    "                    ax.axis(\"off\")\n",
    "                    continue\n",
    "\n",
    "                img_path = _find_image_file(root, trials[0].second_image)\n",
    "                if img_path is None:\n",
    "                    ax.set_title(f\"{cond.upper()} • missing second image\", fontsize=10)\n",
    "                    ax.axis(\"off\")\n",
    "                    continue\n",
    "\n",
    "                sw, sh = screen_default\n",
    "                for t in trials[:3]:\n",
    "                    sw, sh = _screen_dims(t.raw, (sw, sh))\n",
    "\n",
    "                l, ttop, r, b = _image_box_extent(sw, sh, half_box=half_box)\n",
    "                box_size = int(half_box * 2)\n",
    "\n",
    "                img_arr = _load_image_resized(img_path, size_px=box_size)\n",
    "\n",
    "                pts_list = [_extract_fixations(t.raw) for t in trials]\n",
    "                pts = np.vstack([p for p in pts_list if len(p) > 0]) if any(len(p) > 0 for p in pts_list) else np.zeros((0, 2))\n",
    "\n",
    "                heat = _fdm_in_box(pts, l=l, t=ttop, r=r, b=b, size_px=box_size, sigma=sigma)\n",
    "\n",
    "                acc = float(row[\"acc\"])\n",
    "                right = int(row[\"right\"])\n",
    "                wrong = int(row[\"wrong\"])\n",
    "                N = int(row[\"N\"])\n",
    "                n_pairs = int(row[\"n_pairs_in_condition\"])\n",
    "                pair_rank = int(row[\"rank_most_correct\"]) if group_name == \"TOP\" else int(row[\"rank_most_incorrect\"])\n",
    "\n",
    "                title = (\n",
    "                    f\"Testing • {cond.upper()} • Acc: {acc*100:.1f}% • Pair {pair_rank}/{n_pairs}\\n\"\n",
    "                    f\"Second Image • right={right} wrong={wrong} • N={N} • Fix={len(pts)}\"\n",
    "                )\n",
    "\n",
    "                last_hm = _plot_overlay(\n",
    "                    ax=ax,\n",
    "                    img_arr=img_arr,\n",
    "                    pts=pts,\n",
    "                    heat=heat,\n",
    "                    screen_w=sw,\n",
    "                    screen_h=sh,\n",
    "                    extent_ltrb=(l, ttop, r, b),\n",
    "                    title=title,\n",
    "                    heatmap_cmap=heatmap_cmap,\n",
    "                    heatmap_alpha=heatmap_alpha,\n",
    "                    vmax_mode=vmax_mode,\n",
    "                )\n",
    "\n",
    "            fig.suptitle(\n",
    "                f\"Testing Phase • {group_name} {rank_i+1}/{k} • Second Image Only • Heatmap + Fixations\",\n",
    "                fontsize=14,\n",
    "            )\n",
    "\n",
    "            if last_hm is not None:\n",
    "                cbar = fig.colorbar(last_hm, ax=axes.ravel().tolist(), shrink=0.9, pad=0.02)\n",
    "                cbar.set_label(\"Fixation Density\", rotation=90)\n",
    "\n",
    "            pdf.savefig(fig)\n",
    "            plt.close(fig)\n",
    "\n",
    "    if single_pdf:\n",
    "        with PdfPages(combined_pdf) as pdf:\n",
    "            _write_group(pdf, \"TOP\", top)\n",
    "            _write_group(pdf, \"BOTTOM\", bottom)\n",
    "        return combined_pdf, None\n",
    "\n",
    "    with PdfPages(top_pdf) as pdf:\n",
    "        _write_group(pdf, \"TOP\", top)\n",
    "\n",
    "    with PdfPages(bottom_pdf) as pdf:\n",
    "        _write_group(pdf, \"BOTTOM\", bottom)\n",
    "\n",
    "    return top_pdf, bottom_pdf\n",
    "\n",
    "\n",
    "def _running_in_notebook(argv: List[str]) -> bool:\n",
    "    return \"-f\" in argv or \"ipykernel\" in argv[0].lower()\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Export PDFs where each page has 3 panels (FULL/CENTRAL/PERIPHERAL): second image with heatmap+fixations overlaid.\"\n",
    "    )\n",
    "    parser.add_argument(\"--root\", default=\".\", help=\"Folder to search for testing.json and images.\")\n",
    "    parser.add_argument(\"--out\", default=\"plots\", help=\"Output directory.\")\n",
    "    parser.add_argument(\"--k\", type=int, default=3)\n",
    "    parser.add_argument(\"--half-box\", type=int, default=310)\n",
    "    parser.add_argument(\"--screen-w\", type=int, default=1000)\n",
    "    parser.add_argument(\"--screen-h\", type=int, default=800)\n",
    "    parser.add_argument(\"--sigma\", type=float, default=18.0)\n",
    "    parser.add_argument(\"--heatmap-alpha\", type=float, default=0.70)\n",
    "    parser.add_argument(\"--heatmap-cmap\", default=\"turbo\")\n",
    "    parser.add_argument(\"--vmax-mode\", default=\"p99\", choices=[\"p99\", \"max\"])\n",
    "    parser.add_argument(\"--single-pdf\", action=\"store_true\", help=\"If set, outputs one combined PDF (TOPk then BOTTOMk).\")\n",
    "\n",
    "    argv = sys.argv[1:]\n",
    "    if _running_in_notebook(sys.argv):\n",
    "        args = parser.parse_args([])  # ignore Jupyter argv\n",
    "    else:\n",
    "        args, _unknown = parser.parse_known_args(argv)\n",
    "\n",
    "    a, b = export_pdfs(\n",
    "        root_path=args.root,\n",
    "        output_dir=args.out,\n",
    "        k=int(args.k),\n",
    "        half_box=int(args.half_box),\n",
    "        screen_default=(int(args.screen_w), int(args.screen_h)),\n",
    "        sigma=float(args.sigma),\n",
    "        heatmap_alpha=float(args.heatmap_alpha),\n",
    "        heatmap_cmap=str(args.heatmap_cmap),\n",
    "        vmax_mode=str(args.vmax_mode),\n",
    "        single_pdf=bool(args.single_pdf),\n",
    "    )\n",
    "    if b is None:\n",
    "        print(f\"✅ PDF: {a}\")\n",
    "    else:\n",
    "        print(f\"✅ TOP PDF: {a}\")\n",
    "        print(f\"✅ BOTTOM PDF: {b}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2a6b3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PDF: /Users/daisybuathatseephol/Documents/three_json_output/plots/SECOND_IMAGE_OVERLAY_ORDERED_HIGH_TO_LOW.pdf\n"
     ]
    }
   ],
   "source": [
    "# file: scripts/export_second_image_overlay_ordered_accuracy.py\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import re\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Iterable, List, Optional, Sequence, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from PIL import Image\n",
    "\n",
    "try:\n",
    "    from scipy.ndimage import gaussian_filter  # type: ignore\n",
    "except Exception:  # pragma: no cover\n",
    "    gaussian_filter = None\n",
    "\n",
    "\n",
    "CONDITIONS: Tuple[str, ...] = (\"full\", \"central\", \"peripheral\")\n",
    "IMAGE_EXTS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\")\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PairKey:\n",
    "    a: str\n",
    "    b: str\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        return f\"{self.a}__{self.b}\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrialRow:\n",
    "    condition: str\n",
    "    pair: PairKey\n",
    "    first_image: str\n",
    "    second_image: str\n",
    "    correct: Optional[bool]\n",
    "    raw: Dict[str, Any]\n",
    "\n",
    "\n",
    "def _normalize_image_name(name: str) -> str:\n",
    "    s = str(name).strip().lower()\n",
    "    s = re.sub(r\"\\.(jpg|jpeg|png|bmp|tif|tiff)$\", \"\", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "def _clean_condition(x: Any) -> Optional[str]:\n",
    "    if x is None:\n",
    "        return None\n",
    "    s = str(x).strip().lower()\n",
    "    return s if s in CONDITIONS else None\n",
    "\n",
    "\n",
    "def _as_bool(x: Any) -> Optional[bool]:\n",
    "    if x is None:\n",
    "        return None\n",
    "    if isinstance(x, bool):\n",
    "        return x\n",
    "    if isinstance(x, (int, np.integer)) and x in (0, 1):\n",
    "        return bool(x)\n",
    "    if isinstance(x, str):\n",
    "        v = x.strip().lower()\n",
    "        if v in (\"true\", \"t\", \"yes\", \"y\", \"correct\", \"right\", \"1\"):\n",
    "            return True\n",
    "        if v in (\"false\", \"f\", \"no\", \"n\", \"incorrect\", \"wrong\", \"0\"):\n",
    "            return False\n",
    "    return None\n",
    "\n",
    "\n",
    "def _normalize_answer(x: Any) -> Optional[str]:\n",
    "    if x is None:\n",
    "        return None\n",
    "    s = str(x).strip().lower()\n",
    "    return s or None\n",
    "\n",
    "\n",
    "def _detect_correct(item: Dict[str, Any]) -> Optional[bool]:\n",
    "    for k in (\"acc\", \"correct\", \"is_correct\", \"response_correct\", \"trial_correct\", \"accuracy\"):\n",
    "        if k in item:\n",
    "            b = _as_bool(item.get(k))\n",
    "            if b is not None:\n",
    "                return b\n",
    "    subj = _normalize_answer(item.get(\"subj_answer\"))\n",
    "    corr = _normalize_answer(item.get(\"correct_response\"))\n",
    "    if subj is not None and corr is not None:\n",
    "        return subj == corr\n",
    "    return None\n",
    "\n",
    "\n",
    "def _find_testing_json(root: Path) -> Path:\n",
    "    hits = list(root.rglob(\"testing.json\"))\n",
    "    if not hits:\n",
    "        raise FileNotFoundError(f\"❌ testing.json not found under: {root}\")\n",
    "    hits.sort(key=lambda p: (len(p.parts), str(p)))\n",
    "    return hits[0]\n",
    "\n",
    "\n",
    "def _find_image_file(root: Path, image_name: str) -> Optional[Path]:\n",
    "    base = _normalize_image_name(image_name)\n",
    "    candidates: List[Path] = []\n",
    "    for p in root.rglob(\"*\"):\n",
    "        if not p.is_file():\n",
    "            continue\n",
    "        if p.suffix.lower() not in IMAGE_EXTS:\n",
    "            continue\n",
    "        if _normalize_image_name(p.name) == base or _normalize_image_name(p.stem) == base:\n",
    "            candidates.append(p)\n",
    "    if not candidates:\n",
    "        return None\n",
    "    candidates.sort(key=lambda p: (len(p.parts), str(p)))\n",
    "    return candidates[0]\n",
    "\n",
    "\n",
    "def _iter_trials(data: Sequence[Dict[str, Any]]) -> Iterable[TrialRow]:\n",
    "    for item in data:\n",
    "        cond = _clean_condition(item.get(\"viewing_condition\") or item.get(\"condition\"))\n",
    "        if cond is None:\n",
    "            continue\n",
    "        first = item.get(\"first_image\")\n",
    "        second = item.get(\"second_image\")\n",
    "        if not first or not second:\n",
    "            continue\n",
    "\n",
    "        first_s = str(first).strip()\n",
    "        second_s = str(second).strip()\n",
    "        a = _normalize_image_name(first_s)\n",
    "        b = _normalize_image_name(second_s)\n",
    "        pair = PairKey(*sorted((a, b)))\n",
    "\n",
    "        yield TrialRow(\n",
    "            condition=cond,\n",
    "            pair=pair,\n",
    "            first_image=first_s,\n",
    "            second_image=second_s,\n",
    "            correct=_detect_correct(item),\n",
    "            raw=item,\n",
    "        )\n",
    "\n",
    "\n",
    "def _extract_fixations(item: Dict[str, Any]) -> np.ndarray:\n",
    "    xs = item.get(\"fix_x\")\n",
    "    ys = item.get(\"fix_y\")\n",
    "    if not isinstance(xs, (list, tuple)) or not isinstance(ys, (list, tuple)):\n",
    "        return np.zeros((0, 2), dtype=float)\n",
    "    if len(xs) != len(ys) or len(xs) == 0:\n",
    "        return np.zeros((0, 2), dtype=float)\n",
    "    try:\n",
    "        arr = np.column_stack([np.asarray(xs, dtype=float), np.asarray(ys, dtype=float)])\n",
    "        arr = arr[np.isfinite(arr).all(axis=1)]\n",
    "        return arr\n",
    "    except Exception:\n",
    "        return np.zeros((0, 2), dtype=float)\n",
    "\n",
    "\n",
    "def _screen_dims(item: Dict[str, Any], default: Tuple[int, int]) -> Tuple[int, int]:\n",
    "    for kw, kh in (\n",
    "        (\"screen_width\", \"screen_height\"),\n",
    "        (\"window_width\", \"window_height\"),\n",
    "        (\"display_width\", \"display_height\"),\n",
    "        (\"screenW\", \"screenH\"),\n",
    "    ):\n",
    "        if kw in item and kh in item:\n",
    "            try:\n",
    "                w = int(float(item[kw]))\n",
    "                h = int(float(item[kh]))\n",
    "                if w > 0 and h > 0:\n",
    "                    return w, h\n",
    "            except Exception:\n",
    "                pass\n",
    "    return default\n",
    "\n",
    "\n",
    "def _image_box_extent(screen_w: int, screen_h: int, half_box: int) -> Tuple[int, int, int, int]:\n",
    "    l = screen_w // 2 - half_box\n",
    "    t = screen_h // 2 - half_box\n",
    "    r = screen_w // 2 + half_box\n",
    "    b = screen_h // 2 + half_box\n",
    "    return l, t, r, b\n",
    "\n",
    "\n",
    "def _load_image_resized(path: Path, size_px: int) -> np.ndarray:\n",
    "    img = Image.open(path).convert(\"L\")\n",
    "    img = img.resize((size_px, size_px), resample=Image.BICUBIC)\n",
    "    return np.asarray(img)\n",
    "\n",
    "\n",
    "def _fdm_in_box(\n",
    "    pts: np.ndarray,\n",
    "    l: int,\n",
    "    t: int,\n",
    "    r: int,\n",
    "    b: int,\n",
    "    size_px: int,\n",
    "    sigma: float,\n",
    ") -> np.ndarray:\n",
    "    if len(pts) == 0:\n",
    "        return np.zeros((size_px, size_px), dtype=float)\n",
    "\n",
    "    in_box = (pts[:, 0] >= l) & (pts[:, 0] <= r) & (pts[:, 1] >= t) & (pts[:, 1] <= b)\n",
    "    p = pts[in_box]\n",
    "    if len(p) == 0:\n",
    "        return np.zeros((size_px, size_px), dtype=float)\n",
    "\n",
    "    x = (p[:, 0] - l) / max(1e-9, (r - l)) * (size_px - 1)\n",
    "    y = (p[:, 1] - t) / max(1e-9, (b - t)) * (size_px - 1)\n",
    "    x = np.clip(x, 0, size_px - 1)\n",
    "    y = np.clip(y, 0, size_px - 1)\n",
    "\n",
    "    heat, _, _ = np.histogram2d(y, x, bins=[size_px, size_px], range=[[0, size_px], [0, size_px]])\n",
    "    heat = heat.astype(float)\n",
    "\n",
    "    if gaussian_filter is not None:\n",
    "        heat = gaussian_filter(heat, sigma=sigma)\n",
    "    else:\n",
    "        k = int(max(3, math.ceil(sigma * 3)) * 2 + 1)\n",
    "        ax = np.arange(k) - k // 2\n",
    "        kernel = np.exp(-(ax**2) / (2 * sigma**2))\n",
    "        kernel /= kernel.sum()\n",
    "        heat = np.apply_along_axis(lambda m: np.convolve(m, kernel, mode=\"same\"), axis=0, arr=heat)\n",
    "        heat = np.apply_along_axis(lambda m: np.convolve(m, kernel, mode=\"same\"), axis=1, arr=heat)\n",
    "\n",
    "    s = heat.sum()\n",
    "    if s > 0:\n",
    "        heat /= s  # density\n",
    "    return heat\n",
    "\n",
    "\n",
    "def _aggregate_accuracy(trials: Sequence[TrialRow]) -> pd.DataFrame:\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "    for t in trials:\n",
    "        if t.correct is None:\n",
    "            continue\n",
    "        rows.append({\"condition\": t.condition, \"pair\": t.pair.as_str, \"correct\": int(bool(t.correct))})\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        raise ValueError(\"❌ No correctness detected (acc / subj_answer vs correct_response).\")\n",
    "\n",
    "    return (\n",
    "        df.groupby([\"condition\", \"pair\"], as_index=False)\n",
    "        .agg(N=(\"correct\", \"size\"), right=(\"correct\", \"sum\"))\n",
    "        .assign(wrong=lambda x: x[\"N\"] - x[\"right\"])\n",
    "        .assign(acc=lambda x: x[\"right\"] / x[\"N\"])\n",
    "    )\n",
    "\n",
    "\n",
    "def _ranked_lists_by_condition(agg: pd.DataFrame, order: str) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Returns per-condition ordered list with rank_in_order (1..n) and n_pairs.\n",
    "    order: 'high_to_low' or 'low_to_high'\n",
    "    \"\"\"\n",
    "    out: Dict[str, pd.DataFrame] = {}\n",
    "    asc = order == \"low_to_high\"\n",
    "    for cond in CONDITIONS:\n",
    "        sub = agg[agg[\"condition\"] == cond].copy()\n",
    "        sub = sub.sort_values([\"acc\", \"pair\"], ascending=[asc, True]).reset_index(drop=True)\n",
    "        sub[\"rank_in_order\"] = np.arange(1, len(sub) + 1)\n",
    "        sub[\"n_pairs\"] = len(sub)\n",
    "        out[cond] = sub\n",
    "    return out\n",
    "\n",
    "\n",
    "def _collect_trials(all_trials: Sequence[TrialRow], condition: str, pair_str: str) -> List[TrialRow]:\n",
    "    return [t for t in all_trials if t.condition == condition and t.pair.as_str == pair_str]\n",
    "\n",
    "\n",
    "def _plot_overlay(\n",
    "    ax: plt.Axes,\n",
    "    img_arr: np.ndarray,\n",
    "    pts: np.ndarray,\n",
    "    heat: np.ndarray,\n",
    "    screen_w: int,\n",
    "    screen_h: int,\n",
    "    extent_ltrb: Tuple[int, int, int, int],  # (l,t,r,b)\n",
    "    title: str,\n",
    "    heatmap_cmap: str,\n",
    "    heatmap_alpha: float,\n",
    "    vmax_mode: str,\n",
    ") -> Any:\n",
    "    l, t, r, b = extent_ltrb\n",
    "\n",
    "    ax.imshow(img_arr, cmap=\"gray\", origin=\"upper\", extent=(l, r, b, t))\n",
    "\n",
    "    if vmax_mode == \"p99\":\n",
    "        vmax = float(np.quantile(heat, 0.99)) if heat.max() > 0 else 1.0\n",
    "    else:\n",
    "        vmax = float(heat.max()) if heat.max() > 0 else 1.0\n",
    "\n",
    "    hm = ax.imshow(\n",
    "        heat,\n",
    "        origin=\"upper\",\n",
    "        extent=(l, r, b, t),\n",
    "        cmap=heatmap_cmap,\n",
    "        alpha=heatmap_alpha,\n",
    "        vmin=0.0,\n",
    "        vmax=vmax,\n",
    "    )\n",
    "\n",
    "    if len(pts) > 0:\n",
    "        ax.scatter(\n",
    "            pts[:, 0],\n",
    "            pts[:, 1],\n",
    "            s=30,\n",
    "            facecolors=(1.0, 0.42, 0.42, 0.50),\n",
    "            edgecolors=(1.0, 1.0, 1.0, 0.80),\n",
    "            linewidths=0.8,\n",
    "        )\n",
    "\n",
    "    ax.set_xlim(0, screen_w)\n",
    "    ax.set_ylim(screen_h, 0)\n",
    "    ax.set_xlabel(\"x (screen px)\")\n",
    "    ax.set_ylabel(\"y (screen px)\")\n",
    "    ax.set_title(title, fontsize=10)\n",
    "    ax.grid(False)\n",
    "    return hm\n",
    "\n",
    "\n",
    "def export_ordered_accuracy_pdf(\n",
    "    root_path: str,\n",
    "    output_dir: str,\n",
    "    order: str = \"high_to_low\",\n",
    "    max_pages: Optional[int] = None,\n",
    "    half_box: int = 310,\n",
    "    screen_default: Tuple[int, int] = (1000, 800),\n",
    "    sigma: float = 18.0,\n",
    "    heatmap_alpha: float = 0.70,\n",
    "    heatmap_cmap: str = \"turbo\",\n",
    "    vmax_mode: str = \"p99\",\n",
    ") -> Path:\n",
    "    if order not in (\"high_to_low\", \"low_to_high\"):\n",
    "        raise ValueError(\"order must be 'high_to_low' or 'low_to_high'\")\n",
    "\n",
    "    root = Path(root_path).expanduser().resolve()\n",
    "    out_dir = Path(output_dir).expanduser().resolve()\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    json_path = _find_testing_json(root)\n",
    "    data = json.loads(json_path.read_text(encoding=\"utf-8\"))\n",
    "    if not isinstance(data, list):\n",
    "        raise ValueError(\"❌ testing.json must be a list of objects.\")\n",
    "\n",
    "    all_trials = list(_iter_trials(data))\n",
    "    agg = _aggregate_accuracy(all_trials)\n",
    "    agg.to_csv(out_dir / \"accuracy_by_pair_condition.csv\", index=False)\n",
    "\n",
    "    ranked = _ranked_lists_by_condition(agg, order=order)\n",
    "    n_pages = min(len(ranked[c]) for c in CONDITIONS if not ranked[c].empty)\n",
    "    if max_pages is not None:\n",
    "        n_pages = min(n_pages, int(max_pages))\n",
    "\n",
    "    out_pdf = out_dir / f\"SECOND_IMAGE_OVERLAY_ORDERED_{order.upper()}.pdf\"\n",
    "\n",
    "    with PdfPages(out_pdf) as pdf:\n",
    "        for i in range(n_pages):\n",
    "            fig, axes = plt.subplots(1, 3, figsize=(18, 6), constrained_layout=True)\n",
    "            last_hm = None\n",
    "\n",
    "            for col, cond in enumerate(CONDITIONS):\n",
    "                ax = axes[col]\n",
    "                sub = ranked[cond]\n",
    "                row = sub.iloc[i]\n",
    "                pair_str = str(row[\"pair\"])\n",
    "                trials = _collect_trials(all_trials, cond, pair_str)\n",
    "\n",
    "                if not trials:\n",
    "                    ax.set_title(f\"{cond.upper()} • missing trials\", fontsize=10)\n",
    "                    ax.axis(\"off\")\n",
    "                    continue\n",
    "\n",
    "                img_path = _find_image_file(root, trials[0].second_image)\n",
    "                if img_path is None:\n",
    "                    ax.set_title(f\"{cond.upper()} • missing second image\", fontsize=10)\n",
    "                    ax.axis(\"off\")\n",
    "                    continue\n",
    "\n",
    "                sw, sh = screen_default\n",
    "                for t in trials[:3]:\n",
    "                    sw, sh = _screen_dims(t.raw, (sw, sh))\n",
    "\n",
    "                l, ttop, r, b = _image_box_extent(sw, sh, half_box=half_box)\n",
    "                box_size = int(half_box * 2)\n",
    "\n",
    "                img_arr = _load_image_resized(img_path, size_px=box_size)\n",
    "                pts = np.vstack([_extract_fixations(t.raw) for t in trials])\n",
    "                heat = _fdm_in_box(pts, l=l, t=ttop, r=r, b=b, size_px=box_size, sigma=sigma)\n",
    "\n",
    "                acc = float(row[\"acc\"])\n",
    "                right = int(row[\"right\"])\n",
    "                wrong = int(row[\"wrong\"])\n",
    "                N = int(row[\"N\"])\n",
    "                rank_in_order = int(row[\"rank_in_order\"])\n",
    "                n_pairs = int(row[\"n_pairs\"])\n",
    "\n",
    "                title = (\n",
    "                    f\"Testing • {cond.upper()} • Acc: {acc*100:.1f}% • Rank {rank_in_order}/{n_pairs}\\n\"\n",
    "                    f\"Second Image • right={right} wrong={wrong} • N={N} • Fix={len(pts)}\"\n",
    "                )\n",
    "\n",
    "                last_hm = _plot_overlay(\n",
    "                    ax=ax,\n",
    "                    img_arr=img_arr,\n",
    "                    pts=pts,\n",
    "                    heat=heat,\n",
    "                    screen_w=sw,\n",
    "                    screen_h=sh,\n",
    "                    extent_ltrb=(l, ttop, r, b),\n",
    "                    title=title,\n",
    "                    heatmap_cmap=heatmap_cmap,\n",
    "                    heatmap_alpha=heatmap_alpha,\n",
    "                    vmax_mode=vmax_mode,\n",
    "                )\n",
    "\n",
    "            fig.suptitle(\n",
    "                f\"Testing Phase • Ordered by Accuracy ({order.replace('_', '→')}) • Page {i+1}/{n_pages}\",\n",
    "                fontsize=14,\n",
    "            )\n",
    "\n",
    "            if last_hm is not None:\n",
    "                cbar = fig.colorbar(last_hm, ax=axes.ravel().tolist(), shrink=0.9, pad=0.02)\n",
    "                cbar.set_label(\"Fixation Density\", rotation=90)\n",
    "\n",
    "            pdf.savefig(fig)\n",
    "            plt.close(fig)\n",
    "\n",
    "    return out_pdf\n",
    "\n",
    "\n",
    "def _running_in_notebook(argv: List[str]) -> bool:\n",
    "    return \"-f\" in argv or \"ipykernel\" in argv[0].lower()\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"One PDF, pages ordered by accuracy. Each page: 3 panels (full/central/peripheral), second image with heatmap+fixations overlaid.\"\n",
    "    )\n",
    "    parser.add_argument(\"--root\", default=\".\", help=\"Folder to search for testing.json and images.\")\n",
    "    parser.add_argument(\"--out\", default=\"plots\", help=\"Output directory.\")\n",
    "    parser.add_argument(\"--order\", default=\"high_to_low\", choices=[\"high_to_low\", \"low_to_high\"])\n",
    "    parser.add_argument(\"--max-pages\", type=int, default=None, help=\"Optional limit on number of pages (default: all ranks).\")\n",
    "    parser.add_argument(\"--half-box\", type=int, default=310)\n",
    "    parser.add_argument(\"--screen-w\", type=int, default=1000)\n",
    "    parser.add_argument(\"--screen-h\", type=int, default=800)\n",
    "    parser.add_argument(\"--sigma\", type=float, default=18.0)\n",
    "    parser.add_argument(\"--heatmap-alpha\", type=float, default=0.70)\n",
    "    parser.add_argument(\"--heatmap-cmap\", default=\"turbo\")\n",
    "    parser.add_argument(\"--vmax-mode\", default=\"p99\", choices=[\"p99\", \"max\"])\n",
    "\n",
    "    argv = sys.argv[1:]\n",
    "    if _running_in_notebook(sys.argv):\n",
    "        args = parser.parse_args([])  # ignore Jupyter argv\n",
    "    else:\n",
    "        args, _unknown = parser.parse_known_args(argv)\n",
    "\n",
    "    out_pdf = export_ordered_accuracy_pdf(\n",
    "        root_path=args.root,\n",
    "        output_dir=args.out,\n",
    "        order=str(args.order),\n",
    "        max_pages=args.max_pages,\n",
    "        half_box=int(args.half_box),\n",
    "        screen_default=(int(args.screen_w), int(args.screen_h)),\n",
    "        sigma=float(args.sigma),\n",
    "        heatmap_alpha=float(args.heatmap_alpha),\n",
    "        heatmap_cmap=str(args.heatmap_cmap),\n",
    "        vmax_mode=str(args.vmax_mode),\n",
    "    )\n",
    "    print(f\"✅ PDF: {out_pdf}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a572362",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4n/qw3nb3kj7v98xpjkjv1_54pm0000gn/T/ipykernel_8270/1829275953.py:265: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = agg.groupby(\"condition\", group_keys=False).apply(ranker).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PDF: /Users/daisybuathatseephol/Documents/three_json_output/plots/BOTTOM3_EACH_VC_SECOND_IMAGE_OVERLAY.pdf\n"
     ]
    }
   ],
   "source": [
    "# file: scripts/export_bottom3_titles_onepdf.py\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import re\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Iterable, List, Optional, Sequence, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from PIL import Image\n",
    "\n",
    "try:\n",
    "    from scipy.ndimage import gaussian_filter  # type: ignore\n",
    "except Exception:  # pragma: no cover\n",
    "    gaussian_filter = None\n",
    "\n",
    "\n",
    "CONDITIONS: Tuple[str, ...] = (\"full\", \"central\", \"peripheral\")\n",
    "IMAGE_EXTS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\")\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PairKey:\n",
    "    a: str\n",
    "    b: str\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        return f\"{self.a}__{self.b}\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrialRow:\n",
    "    condition: str\n",
    "    pair: PairKey\n",
    "    first_image: str\n",
    "    second_image: str\n",
    "    correct: Optional[bool]\n",
    "    raw: Dict[str, Any]\n",
    "\n",
    "\n",
    "def _normalize_image_name(name: str) -> str:\n",
    "    s = str(name).strip().lower()\n",
    "    s = re.sub(r\"\\.(jpg|jpeg|png|bmp|tif|tiff)$\", \"\", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "def _clean_condition(x: Any) -> Optional[str]:\n",
    "    if x is None:\n",
    "        return None\n",
    "    s = str(x).strip().lower()\n",
    "    return s if s in CONDITIONS else None\n",
    "\n",
    "\n",
    "def _as_bool(x: Any) -> Optional[bool]:\n",
    "    if x is None:\n",
    "        return None\n",
    "    if isinstance(x, bool):\n",
    "        return x\n",
    "    if isinstance(x, (int, np.integer)) and x in (0, 1):\n",
    "        return bool(x)\n",
    "    if isinstance(x, str):\n",
    "        v = x.strip().lower()\n",
    "        if v in (\"true\", \"t\", \"yes\", \"y\", \"correct\", \"right\", \"1\"):\n",
    "            return True\n",
    "        if v in (\"false\", \"f\", \"no\", \"n\", \"incorrect\", \"wrong\", \"0\"):\n",
    "            return False\n",
    "    return None\n",
    "\n",
    "\n",
    "def _normalize_answer(x: Any) -> Optional[str]:\n",
    "    if x is None:\n",
    "        return None\n",
    "    s = str(x).strip().lower()\n",
    "    return s or None\n",
    "\n",
    "\n",
    "def _detect_correct(item: Dict[str, Any]) -> Optional[bool]:\n",
    "    for k in (\"acc\", \"correct\", \"is_correct\", \"response_correct\", \"trial_correct\", \"accuracy\"):\n",
    "        if k in item:\n",
    "            b = _as_bool(item.get(k))\n",
    "            if b is not None:\n",
    "                return b\n",
    "    subj = _normalize_answer(item.get(\"subj_answer\"))\n",
    "    corr = _normalize_answer(item.get(\"correct_response\"))\n",
    "    if subj is not None and corr is not None:\n",
    "        return subj == corr\n",
    "    return None\n",
    "\n",
    "\n",
    "def _find_testing_json(root: Path) -> Path:\n",
    "    hits = list(root.rglob(\"testing.json\"))\n",
    "    if not hits:\n",
    "        raise FileNotFoundError(f\"❌ testing.json not found under: {root}\")\n",
    "    hits.sort(key=lambda p: (len(p.parts), str(p)))\n",
    "    return hits[0]\n",
    "\n",
    "\n",
    "def _find_image_file(root: Path, image_name: str) -> Optional[Path]:\n",
    "    base = _normalize_image_name(image_name)\n",
    "    candidates: List[Path] = []\n",
    "    for p in root.rglob(\"*\"):\n",
    "        if not p.is_file():\n",
    "            continue\n",
    "        if p.suffix.lower() not in IMAGE_EXTS:\n",
    "            continue\n",
    "        if _normalize_image_name(p.name) == base or _normalize_image_name(p.stem) == base:\n",
    "            candidates.append(p)\n",
    "    if not candidates:\n",
    "        return None\n",
    "    candidates.sort(key=lambda p: (len(p.parts), str(p)))\n",
    "    return candidates[0]\n",
    "\n",
    "\n",
    "def _iter_trials(data: Sequence[Dict[str, Any]]) -> Iterable[TrialRow]:\n",
    "    for item in data:\n",
    "        cond = _clean_condition(item.get(\"viewing_condition\") or item.get(\"condition\"))\n",
    "        if cond is None:\n",
    "            continue\n",
    "\n",
    "        first = item.get(\"first_image\")\n",
    "        second = item.get(\"second_image\")\n",
    "        if not first or not second:\n",
    "            continue\n",
    "\n",
    "        first_s = str(first).strip()\n",
    "        second_s = str(second).strip()\n",
    "\n",
    "        a = _normalize_image_name(first_s)\n",
    "        b = _normalize_image_name(second_s)\n",
    "        pair = PairKey(*sorted((a, b)))\n",
    "\n",
    "        yield TrialRow(\n",
    "            condition=cond,\n",
    "            pair=pair,\n",
    "            first_image=first_s,\n",
    "            second_image=second_s,\n",
    "            correct=_detect_correct(item),\n",
    "            raw=item,\n",
    "        )\n",
    "\n",
    "\n",
    "def _extract_fixations(item: Dict[str, Any]) -> np.ndarray:\n",
    "    xs = item.get(\"fix_x\")\n",
    "    ys = item.get(\"fix_y\")\n",
    "    if not isinstance(xs, (list, tuple)) or not isinstance(ys, (list, tuple)):\n",
    "        return np.zeros((0, 2), dtype=float)\n",
    "    if len(xs) != len(ys) or len(xs) == 0:\n",
    "        return np.zeros((0, 2), dtype=float)\n",
    "    try:\n",
    "        arr = np.column_stack([np.asarray(xs, dtype=float), np.asarray(ys, dtype=float)])\n",
    "        arr = arr[np.isfinite(arr).all(axis=1)]\n",
    "        return arr\n",
    "    except Exception:\n",
    "        return np.zeros((0, 2), dtype=float)\n",
    "\n",
    "\n",
    "def _screen_dims(item: Dict[str, Any], default: Tuple[int, int]) -> Tuple[int, int]:\n",
    "    for kw, kh in (\n",
    "        (\"screen_width\", \"screen_height\"),\n",
    "        (\"window_width\", \"window_height\"),\n",
    "        (\"display_width\", \"display_height\"),\n",
    "        (\"screenW\", \"screenH\"),\n",
    "    ):\n",
    "        if kw in item and kh in item:\n",
    "            try:\n",
    "                w = int(float(item[kw]))\n",
    "                h = int(float(item[kh]))\n",
    "                if w > 0 and h > 0:\n",
    "                    return w, h\n",
    "            except Exception:\n",
    "                pass\n",
    "    return default\n",
    "\n",
    "\n",
    "def _image_box_extent(screen_w: int, screen_h: int, half_box: int) -> Tuple[int, int, int, int]:\n",
    "    l = screen_w // 2 - half_box\n",
    "    t = screen_h // 2 - half_box\n",
    "    r = screen_w // 2 + half_box\n",
    "    b = screen_h // 2 + half_box\n",
    "    return l, t, r, b\n",
    "\n",
    "\n",
    "def _load_image_resized(path: Path, size_px: int) -> np.ndarray:\n",
    "    img = Image.open(path).convert(\"L\")\n",
    "    img = img.resize((size_px, size_px), resample=Image.BICUBIC)\n",
    "    return np.asarray(img)\n",
    "\n",
    "\n",
    "def _fdm_in_box(\n",
    "    pts: np.ndarray,\n",
    "    l: int,\n",
    "    t: int,\n",
    "    r: int,\n",
    "    b: int,\n",
    "    size_px: int,\n",
    "    sigma: float,\n",
    ") -> np.ndarray:\n",
    "    if len(pts) == 0:\n",
    "        return np.zeros((size_px, size_px), dtype=float)\n",
    "\n",
    "    in_box = (pts[:, 0] >= l) & (pts[:, 0] <= r) & (pts[:, 1] >= t) & (pts[:, 1] <= b)\n",
    "    p = pts[in_box]\n",
    "    if len(p) == 0:\n",
    "        return np.zeros((size_px, size_px), dtype=float)\n",
    "\n",
    "    x = (p[:, 0] - l) / max(1e-9, (r - l)) * (size_px - 1)\n",
    "    y = (p[:, 1] - t) / max(1e-9, (b - t)) * (size_px - 1)\n",
    "    x = np.clip(x, 0, size_px - 1)\n",
    "    y = np.clip(y, 0, size_px - 1)\n",
    "\n",
    "    heat, _, _ = np.histogram2d(y, x, bins=[size_px, size_px], range=[[0, size_px], [0, size_px]])\n",
    "    heat = heat.astype(float)\n",
    "\n",
    "    if gaussian_filter is not None:\n",
    "        heat = gaussian_filter(heat, sigma=sigma)\n",
    "    else:\n",
    "        k = int(max(3, math.ceil(sigma * 3)) * 2 + 1)\n",
    "        ax = np.arange(k) - k // 2\n",
    "        kernel = np.exp(-(ax**2) / (2 * sigma**2))\n",
    "        kernel /= kernel.sum()\n",
    "        heat = np.apply_along_axis(lambda m: np.convolve(m, kernel, mode=\"same\"), axis=0, arr=heat)\n",
    "        heat = np.apply_along_axis(lambda m: np.convolve(m, kernel, mode=\"same\"), axis=1, arr=heat)\n",
    "\n",
    "    s = heat.sum()\n",
    "    if s > 0:\n",
    "        heat /= s\n",
    "    return heat\n",
    "\n",
    "\n",
    "def _aggregate_accuracy(trials: Sequence[TrialRow]) -> pd.DataFrame:\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "    for t in trials:\n",
    "        if t.correct is None:\n",
    "            continue\n",
    "        rows.append({\"condition\": t.condition, \"pair\": t.pair.as_str, \"correct\": int(bool(t.correct))})\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        raise ValueError(\"❌ No correctness detected (acc / subj_answer vs correct_response).\")\n",
    "\n",
    "    return (\n",
    "        df.groupby([\"condition\", \"pair\"], as_index=False)\n",
    "        .agg(N=(\"correct\", \"size\"), right=(\"correct\", \"sum\"))\n",
    "        .assign(wrong=lambda x: x[\"N\"] - x[\"right\"])\n",
    "        .assign(acc=lambda x: x[\"right\"] / x[\"N\"])\n",
    "    )\n",
    "\n",
    "\n",
    "def _rank_most_incorrect(agg: pd.DataFrame) -> pd.DataFrame:\n",
    "    def ranker(group: pd.DataFrame) -> pd.DataFrame:\n",
    "        g = group.sort_values([\"acc\", \"pair\"], ascending=[True, True]).reset_index(drop=True)\n",
    "        g[\"pair_rank_incorrect\"] = np.arange(1, len(g) + 1)\n",
    "        g[\"n_pairs\"] = len(g)\n",
    "        return g\n",
    "\n",
    "    out = agg.groupby(\"condition\", group_keys=False).apply(ranker).reset_index(drop=True)\n",
    "    out[\"condition\"] = pd.Categorical(out[\"condition\"], categories=list(CONDITIONS), ordered=True)\n",
    "    return out\n",
    "\n",
    "\n",
    "def _collect_trials(all_trials: Sequence[TrialRow], condition: str, pair_str: str) -> List[TrialRow]:\n",
    "    return [t for t in all_trials if t.condition == condition and t.pair.as_str == pair_str]\n",
    "\n",
    "\n",
    "def _plot_overlay(\n",
    "    ax: plt.Axes,\n",
    "    img_arr: np.ndarray,\n",
    "    pts: np.ndarray,\n",
    "    heat: np.ndarray,\n",
    "    screen_w: int,\n",
    "    screen_h: int,\n",
    "    extent_ltrb: Tuple[int, int, int, int],  # (l,t,r,b)\n",
    "    title1: str,\n",
    "    title2: str,\n",
    "    heatmap_cmap: str,\n",
    "    heatmap_alpha: float,\n",
    "    vmax_mode: str,\n",
    ") -> Any:\n",
    "    l, t, r, b = extent_ltrb\n",
    "\n",
    "    ax.imshow(img_arr, cmap=\"gray\", origin=\"upper\", extent=(l, r, b, t))\n",
    "\n",
    "    if vmax_mode == \"p99\":\n",
    "        vmax = float(np.quantile(heat, 0.99)) if heat.max() > 0 else 1.0\n",
    "    else:\n",
    "        vmax = float(heat.max()) if heat.max() > 0 else 1.0\n",
    "\n",
    "    hm = ax.imshow(\n",
    "        heat,\n",
    "        origin=\"upper\",\n",
    "        extent=(l, r, b, t),\n",
    "        cmap=heatmap_cmap,\n",
    "        alpha=heatmap_alpha,\n",
    "        vmin=0.0,\n",
    "        vmax=vmax,\n",
    "    )\n",
    "\n",
    "    if len(pts) > 0:\n",
    "        ax.scatter(\n",
    "            pts[:, 0],\n",
    "            pts[:, 1],\n",
    "            s=30,\n",
    "            facecolors=(1.0, 0.42, 0.42, 0.50),\n",
    "            edgecolors=(1.0, 1.0, 1.0, 0.80),\n",
    "            linewidths=0.8,\n",
    "        )\n",
    "\n",
    "    ax.set_xlim(0, screen_w)\n",
    "    ax.set_ylim(screen_h, 0)\n",
    "    ax.set_xlabel(\"x (screen px)\")\n",
    "    ax.set_ylabel(\"y (screen px)\")\n",
    "    ax.set_title(f\"{title1}\\n{title2}\", fontsize=10)\n",
    "    ax.grid(False)\n",
    "    return hm\n",
    "\n",
    "\n",
    "def export_bottom3_each_condition_one_pdf(\n",
    "    root_path: str,\n",
    "    output_dir: str,\n",
    "    half_box: int = 310,\n",
    "    screen_default: Tuple[int, int] = (1000, 800),\n",
    "    sigma: float = 18.0,\n",
    "    heatmap_alpha: float = 0.70,\n",
    "    heatmap_cmap: str = \"turbo\",\n",
    "    vmax_mode: str = \"p99\",\n",
    ") -> Path:\n",
    "    root = Path(root_path).expanduser().resolve()\n",
    "    out_dir = Path(output_dir).expanduser().resolve()\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    json_path = _find_testing_json(root)\n",
    "    data = json.loads(json_path.read_text(encoding=\"utf-8\"))\n",
    "    if not isinstance(data, list):\n",
    "        raise ValueError(\"❌ testing.json must be a list of objects.\")\n",
    "\n",
    "    all_trials = list(_iter_trials(data))\n",
    "    agg = _aggregate_accuracy(all_trials)\n",
    "    ranked = _rank_most_incorrect(agg)\n",
    "    ranked.to_csv(out_dir / \"accuracy_by_pair_condition.csv\", index=False)\n",
    "\n",
    "    out_pdf = out_dir / \"BOTTOM3_EACH_VC_SECOND_IMAGE_OVERLAY.pdf\"\n",
    "\n",
    "    with PdfPages(out_pdf) as pdf:\n",
    "        for cond in CONDITIONS:\n",
    "            sub = ranked[ranked[\"condition\"] == cond].sort_values(\n",
    "                [\"acc\", \"pair\"], ascending=[True, True]\n",
    "            ).head(3)\n",
    "\n",
    "            fig, axes = plt.subplots(1, 3, figsize=(18, 6), constrained_layout=True)\n",
    "            last_hm = None\n",
    "\n",
    "            for j, (_, row) in enumerate(sub.iterrows()):\n",
    "                ax = axes[j]\n",
    "\n",
    "                pair_str = str(row[\"pair\"])\n",
    "                trials = _collect_trials(all_trials, cond, pair_str)\n",
    "                if not trials:\n",
    "                    ax.axis(\"off\")\n",
    "                    continue\n",
    "\n",
    "                img_path = _find_image_file(root, trials[0].second_image)\n",
    "                if img_path is None:\n",
    "                    ax.set_title(f\"{cond.upper()} • missing second image\", fontsize=10)\n",
    "                    ax.axis(\"off\")\n",
    "                    continue\n",
    "\n",
    "                sw, sh = screen_default\n",
    "                for t in trials[:3]:\n",
    "                    sw, sh = _screen_dims(t.raw, (sw, sh))\n",
    "\n",
    "                l, ttop, r, b = _image_box_extent(sw, sh, half_box=half_box)\n",
    "                box_size = int(half_box * 2)\n",
    "\n",
    "                img_arr = _load_image_resized(img_path, size_px=box_size)\n",
    "\n",
    "                pts = np.vstack([_extract_fixations(t.raw) for t in trials])\n",
    "                heat = _fdm_in_box(pts, l=l, t=ttop, r=r, b=b, size_px=box_size, sigma=sigma)\n",
    "\n",
    "                acc = float(row[\"acc\"])\n",
    "                right = int(row[\"right\"])\n",
    "                wrong = int(row[\"wrong\"])\n",
    "                N = int(row[\"N\"])\n",
    "                pair_rank = int(row[\"pair_rank_incorrect\"])\n",
    "                n_pairs = int(row[\"n_pairs\"])\n",
    "\n",
    "                correctness_label = \"Correct\" if acc >= 0.5 else \"Incorrect\"\n",
    "\n",
    "                title1 = f\"Testing • Acc: {acc*100:.1f}% • Pair {pair_rank}/{n_pairs} • {correctness_label}\"\n",
    "                title2 = f\"Subjects: right={right} • wrong={wrong} • N={N} subjects • Second: {len(pts)} fix\"\n",
    "\n",
    "                last_hm = _plot_overlay(\n",
    "                    ax=ax,\n",
    "                    img_arr=img_arr,\n",
    "                    pts=pts,\n",
    "                    heat=heat,\n",
    "                    screen_w=sw,\n",
    "                    screen_h=sh,\n",
    "                    extent_ltrb=(l, ttop, r, b),\n",
    "                    title1=title1,\n",
    "                    title2=title2,\n",
    "                    heatmap_cmap=heatmap_cmap,\n",
    "                    heatmap_alpha=heatmap_alpha,\n",
    "                    vmax_mode=vmax_mode,\n",
    "                )\n",
    "\n",
    "            # If fewer than 3, hide remaining axes\n",
    "            for k in range(len(sub), 3):\n",
    "                axes[k].axis(\"off\")\n",
    "\n",
    "            fig.suptitle(\n",
    "                f\"Testing Phase - {cond.upper()} Viewing Condition\\n\"\n",
    "                f\"Bottom 3 Trials (Low Accuracy)\\n\"\n",
    "                f\"Ordered from Most Incorrect \\u2192 Least Incorrect\",\n",
    "                fontsize=14,\n",
    "                fontweight=\"bold\",\n",
    "            )\n",
    "\n",
    "            if last_hm is not None:\n",
    "                cbar = fig.colorbar(last_hm, ax=axes.ravel().tolist(), shrink=0.9, pad=0.02)\n",
    "                cbar.set_label(\"Fixation Density\", rotation=90)\n",
    "\n",
    "            pdf.savefig(fig)\n",
    "            plt.close(fig)\n",
    "\n",
    "    return out_pdf\n",
    "\n",
    "\n",
    "def _running_in_notebook(argv: List[str]) -> bool:\n",
    "    return \"-f\" in argv or \"ipykernel\" in argv[0].lower()\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"One PDF, 3 pages (full/central/peripheral). Each page shows bottom 3 pairs (most incorrect->least incorrect) with titles like your example.\"\n",
    "    )\n",
    "    parser.add_argument(\"--root\", default=\".\", help=\"Folder to search for testing.json and images.\")\n",
    "    parser.add_argument(\"--out\", default=\"plots\", help=\"Output directory.\")\n",
    "    parser.add_argument(\"--half-box\", type=int, default=310)\n",
    "    parser.add_argument(\"--screen-w\", type=int, default=1000)\n",
    "    parser.add_argument(\"--screen-h\", type=int, default=800)\n",
    "    parser.add_argument(\"--sigma\", type=float, default=18.0)\n",
    "    parser.add_argument(\"--heatmap-alpha\", type=float, default=0.70)\n",
    "    parser.add_argument(\"--heatmap-cmap\", default=\"turbo\")\n",
    "    parser.add_argument(\"--vmax-mode\", default=\"p99\", choices=[\"p99\", \"max\"])\n",
    "\n",
    "    argv = sys.argv[1:]\n",
    "    if _running_in_notebook(sys.argv):\n",
    "        args = parser.parse_args([])  # ignore Jupyter argv\n",
    "    else:\n",
    "        args, _unknown = parser.parse_known_args(argv)\n",
    "\n",
    "    out_pdf = export_bottom3_each_condition_one_pdf(\n",
    "        root_path=args.root,\n",
    "        output_dir=args.out,\n",
    "        half_box=int(args.half_box),\n",
    "        screen_default=(int(args.screen_w), int(args.screen_h)),\n",
    "        sigma=float(args.sigma),\n",
    "        heatmap_alpha=float(args.heatmap_alpha),\n",
    "        heatmap_cmap=str(args.heatmap_cmap),\n",
    "        vmax_mode=str(args.vmax_mode),\n",
    "    )\n",
    "    print(f\"✅ PDF: {out_pdf}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32d5df71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4n/qw3nb3kj7v98xpjkjv1_54pm0000gn/T/ipykernel_8270/3247403863.py:265: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = agg.groupby(\"condition\", group_keys=False).apply(ranker).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PDF: /Users/daisybuathatseephol/Documents/three_json_output/plots/TOP3_EACH_VC_SECOND_IMAGE_OVERLAY.pdf\n"
     ]
    }
   ],
   "source": [
    "# file: scripts/export_top3_titles_onepdf.py\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import re\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Iterable, List, Optional, Sequence, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from PIL import Image\n",
    "\n",
    "try:\n",
    "    from scipy.ndimage import gaussian_filter  # type: ignore\n",
    "except Exception:  # pragma: no cover\n",
    "    gaussian_filter = None\n",
    "\n",
    "\n",
    "CONDITIONS: Tuple[str, ...] = (\"full\", \"central\", \"peripheral\")\n",
    "IMAGE_EXTS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\")\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PairKey:\n",
    "    a: str\n",
    "    b: str\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        return f\"{self.a}__{self.b}\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrialRow:\n",
    "    condition: str\n",
    "    pair: PairKey\n",
    "    first_image: str\n",
    "    second_image: str\n",
    "    correct: Optional[bool]\n",
    "    raw: Dict[str, Any]\n",
    "\n",
    "\n",
    "def _normalize_image_name(name: str) -> str:\n",
    "    s = str(name).strip().lower()\n",
    "    s = re.sub(r\"\\.(jpg|jpeg|png|bmp|tif|tiff)$\", \"\", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "def _clean_condition(x: Any) -> Optional[str]:\n",
    "    if x is None:\n",
    "        return None\n",
    "    s = str(x).strip().lower()\n",
    "    return s if s in CONDITIONS else None\n",
    "\n",
    "\n",
    "def _as_bool(x: Any) -> Optional[bool]:\n",
    "    if x is None:\n",
    "        return None\n",
    "    if isinstance(x, bool):\n",
    "        return x\n",
    "    if isinstance(x, (int, np.integer)) and x in (0, 1):\n",
    "        return bool(x)\n",
    "    if isinstance(x, str):\n",
    "        v = x.strip().lower()\n",
    "        if v in (\"true\", \"t\", \"yes\", \"y\", \"correct\", \"right\", \"1\"):\n",
    "            return True\n",
    "        if v in (\"false\", \"f\", \"no\", \"n\", \"incorrect\", \"wrong\", \"0\"):\n",
    "            return False\n",
    "    return None\n",
    "\n",
    "\n",
    "def _normalize_answer(x: Any) -> Optional[str]:\n",
    "    if x is None:\n",
    "        return None\n",
    "    s = str(x).strip().lower()\n",
    "    return s or None\n",
    "\n",
    "\n",
    "def _detect_correct(item: Dict[str, Any]) -> Optional[bool]:\n",
    "    for k in (\"acc\", \"correct\", \"is_correct\", \"response_correct\", \"trial_correct\", \"accuracy\"):\n",
    "        if k in item:\n",
    "            b = _as_bool(item.get(k))\n",
    "            if b is not None:\n",
    "                return b\n",
    "    subj = _normalize_answer(item.get(\"subj_answer\"))\n",
    "    corr = _normalize_answer(item.get(\"correct_response\"))\n",
    "    if subj is not None and corr is not None:\n",
    "        return subj == corr\n",
    "    return None\n",
    "\n",
    "\n",
    "def _find_testing_json(root: Path) -> Path:\n",
    "    hits = list(root.rglob(\"testing.json\"))\n",
    "    if not hits:\n",
    "        raise FileNotFoundError(f\"❌ testing.json not found under: {root}\")\n",
    "    hits.sort(key=lambda p: (len(p.parts), str(p)))\n",
    "    return hits[0]\n",
    "\n",
    "\n",
    "def _find_image_file(root: Path, image_name: str) -> Optional[Path]:\n",
    "    base = _normalize_image_name(image_name)\n",
    "    candidates: List[Path] = []\n",
    "    for p in root.rglob(\"*\"):\n",
    "        if not p.is_file():\n",
    "            continue\n",
    "        if p.suffix.lower() not in IMAGE_EXTS:\n",
    "            continue\n",
    "        if _normalize_image_name(p.name) == base or _normalize_image_name(p.stem) == base:\n",
    "            candidates.append(p)\n",
    "    if not candidates:\n",
    "        return None\n",
    "    candidates.sort(key=lambda p: (len(p.parts), str(p)))\n",
    "    return candidates[0]\n",
    "\n",
    "\n",
    "def _iter_trials(data: Sequence[Dict[str, Any]]) -> Iterable[TrialRow]:\n",
    "    for item in data:\n",
    "        cond = _clean_condition(item.get(\"viewing_condition\") or item.get(\"condition\"))\n",
    "        if cond is None:\n",
    "            continue\n",
    "\n",
    "        first = item.get(\"first_image\")\n",
    "        second = item.get(\"second_image\")\n",
    "        if not first or not second:\n",
    "            continue\n",
    "\n",
    "        first_s = str(first).strip()\n",
    "        second_s = str(second).strip()\n",
    "\n",
    "        a = _normalize_image_name(first_s)\n",
    "        b = _normalize_image_name(second_s)\n",
    "        pair = PairKey(*sorted((a, b)))\n",
    "\n",
    "        yield TrialRow(\n",
    "            condition=cond,\n",
    "            pair=pair,\n",
    "            first_image=first_s,\n",
    "            second_image=second_s,\n",
    "            correct=_detect_correct(item),\n",
    "            raw=item,\n",
    "        )\n",
    "\n",
    "\n",
    "def _extract_fixations(item: Dict[str, Any]) -> np.ndarray:\n",
    "    xs = item.get(\"fix_x\")\n",
    "    ys = item.get(\"fix_y\")\n",
    "    if not isinstance(xs, (list, tuple)) or not isinstance(ys, (list, tuple)):\n",
    "        return np.zeros((0, 2), dtype=float)\n",
    "    if len(xs) != len(ys) or len(xs) == 0:\n",
    "        return np.zeros((0, 2), dtype=float)\n",
    "    try:\n",
    "        arr = np.column_stack([np.asarray(xs, dtype=float), np.asarray(ys, dtype=float)])\n",
    "        arr = arr[np.isfinite(arr).all(axis=1)]\n",
    "        return arr\n",
    "    except Exception:\n",
    "        return np.zeros((0, 2), dtype=float)\n",
    "\n",
    "\n",
    "def _screen_dims(item: Dict[str, Any], default: Tuple[int, int]) -> Tuple[int, int]:\n",
    "    for kw, kh in (\n",
    "        (\"screen_width\", \"screen_height\"),\n",
    "        (\"window_width\", \"window_height\"),\n",
    "        (\"display_width\", \"display_height\"),\n",
    "        (\"screenW\", \"screenH\"),\n",
    "    ):\n",
    "        if kw in item and kh in item:\n",
    "            try:\n",
    "                w = int(float(item[kw]))\n",
    "                h = int(float(item[kh]))\n",
    "                if w > 0 and h > 0:\n",
    "                    return w, h\n",
    "            except Exception:\n",
    "                pass\n",
    "    return default\n",
    "\n",
    "\n",
    "def _image_box_extent(screen_w: int, screen_h: int, half_box: int) -> Tuple[int, int, int, int]:\n",
    "    l = screen_w // 2 - half_box\n",
    "    t = screen_h // 2 - half_box\n",
    "    r = screen_w // 2 + half_box\n",
    "    b = screen_h // 2 + half_box\n",
    "    return l, t, r, b\n",
    "\n",
    "\n",
    "def _load_image_resized(path: Path, size_px: int) -> np.ndarray:\n",
    "    img = Image.open(path).convert(\"L\")\n",
    "    img = img.resize((size_px, size_px), resample=Image.BICUBIC)\n",
    "    return np.asarray(img)\n",
    "\n",
    "\n",
    "def _fdm_in_box(\n",
    "    pts: np.ndarray,\n",
    "    l: int,\n",
    "    t: int,\n",
    "    r: int,\n",
    "    b: int,\n",
    "    size_px: int,\n",
    "    sigma: float,\n",
    ") -> np.ndarray:\n",
    "    if len(pts) == 0:\n",
    "        return np.zeros((size_px, size_px), dtype=float)\n",
    "\n",
    "    in_box = (pts[:, 0] >= l) & (pts[:, 0] <= r) & (pts[:, 1] >= t) & (pts[:, 1] <= b)\n",
    "    p = pts[in_box]\n",
    "    if len(p) == 0:\n",
    "        return np.zeros((size_px, size_px), dtype=float)\n",
    "\n",
    "    x = (p[:, 0] - l) / max(1e-9, (r - l)) * (size_px - 1)\n",
    "    y = (p[:, 1] - t) / max(1e-9, (b - t)) * (size_px - 1)\n",
    "    x = np.clip(x, 0, size_px - 1)\n",
    "    y = np.clip(y, 0, size_px - 1)\n",
    "\n",
    "    heat, _, _ = np.histogram2d(y, x, bins=[size_px, size_px], range=[[0, size_px], [0, size_px]])\n",
    "    heat = heat.astype(float)\n",
    "\n",
    "    if gaussian_filter is not None:\n",
    "        heat = gaussian_filter(heat, sigma=sigma)\n",
    "    else:\n",
    "        k = int(max(3, math.ceil(sigma * 3)) * 2 + 1)\n",
    "        ax = np.arange(k) - k // 2\n",
    "        kernel = np.exp(-(ax**2) / (2 * sigma**2))\n",
    "        kernel /= kernel.sum()\n",
    "        heat = np.apply_along_axis(lambda m: np.convolve(m, kernel, mode=\"same\"), axis=0, arr=heat)\n",
    "        heat = np.apply_along_axis(lambda m: np.convolve(m, kernel, mode=\"same\"), axis=1, arr=heat)\n",
    "\n",
    "    s = heat.sum()\n",
    "    if s > 0:\n",
    "        heat /= s\n",
    "    return heat\n",
    "\n",
    "\n",
    "def _aggregate_accuracy(trials: Sequence[TrialRow]) -> pd.DataFrame:\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "    for t in trials:\n",
    "        if t.correct is None:\n",
    "            continue\n",
    "        rows.append({\"condition\": t.condition, \"pair\": t.pair.as_str, \"correct\": int(bool(t.correct))})\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        raise ValueError(\"❌ No correctness detected (acc / subj_answer vs correct_response).\")\n",
    "\n",
    "    return (\n",
    "        df.groupby([\"condition\", \"pair\"], as_index=False)\n",
    "        .agg(N=(\"correct\", \"size\"), right=(\"correct\", \"sum\"))\n",
    "        .assign(wrong=lambda x: x[\"N\"] - x[\"right\"])\n",
    "        .assign(acc=lambda x: x[\"right\"] / x[\"N\"])\n",
    "    )\n",
    "\n",
    "\n",
    "def _rank_most_correct(agg: pd.DataFrame) -> pd.DataFrame:\n",
    "    def ranker(group: pd.DataFrame) -> pd.DataFrame:\n",
    "        g = group.sort_values([\"acc\", \"pair\"], ascending=[False, True]).reset_index(drop=True)\n",
    "        g[\"pair_rank_correct\"] = np.arange(1, len(g) + 1)\n",
    "        g[\"n_pairs\"] = len(g)\n",
    "        return g\n",
    "\n",
    "    out = agg.groupby(\"condition\", group_keys=False).apply(ranker).reset_index(drop=True)\n",
    "    out[\"condition\"] = pd.Categorical(out[\"condition\"], categories=list(CONDITIONS), ordered=True)\n",
    "    return out\n",
    "\n",
    "\n",
    "def _collect_trials(all_trials: Sequence[TrialRow], condition: str, pair_str: str) -> List[TrialRow]:\n",
    "    return [t for t in all_trials if t.condition == condition and t.pair.as_str == pair_str]\n",
    "\n",
    "\n",
    "def _plot_overlay(\n",
    "    ax: plt.Axes,\n",
    "    img_arr: np.ndarray,\n",
    "    pts: np.ndarray,\n",
    "    heat: np.ndarray,\n",
    "    screen_w: int,\n",
    "    screen_h: int,\n",
    "    extent_ltrb: Tuple[int, int, int, int],  # (l,t,r,b)\n",
    "    title1: str,\n",
    "    title2: str,\n",
    "    heatmap_cmap: str,\n",
    "    heatmap_alpha: float,\n",
    "    vmax_mode: str,\n",
    ") -> Any:\n",
    "    l, t, r, b = extent_ltrb\n",
    "    ax.imshow(img_arr, cmap=\"gray\", origin=\"upper\", extent=(l, r, b, t))\n",
    "\n",
    "    if vmax_mode == \"p99\":\n",
    "        vmax = float(np.quantile(heat, 0.99)) if heat.max() > 0 else 1.0\n",
    "    else:\n",
    "        vmax = float(heat.max()) if heat.max() > 0 else 1.0\n",
    "\n",
    "    hm = ax.imshow(\n",
    "        heat,\n",
    "        origin=\"upper\",\n",
    "        extent=(l, r, b, t),\n",
    "        cmap=heatmap_cmap,\n",
    "        alpha=heatmap_alpha,\n",
    "        vmin=0.0,\n",
    "        vmax=vmax,\n",
    "    )\n",
    "\n",
    "    if len(pts) > 0:\n",
    "        ax.scatter(\n",
    "            pts[:, 0],\n",
    "            pts[:, 1],\n",
    "            s=30,\n",
    "            facecolors=(1.0, 0.42, 0.42, 0.50),\n",
    "            edgecolors=(1.0, 1.0, 1.0, 0.80),\n",
    "            linewidths=0.8,\n",
    "        )\n",
    "\n",
    "    ax.set_xlim(0, screen_w)\n",
    "    ax.set_ylim(screen_h, 0)\n",
    "    ax.set_xlabel(\"x (screen px)\")\n",
    "    ax.set_ylabel(\"y (screen px)\")\n",
    "    ax.set_title(f\"{title1}\\n{title2}\", fontsize=10)\n",
    "    ax.grid(False)\n",
    "    return hm\n",
    "\n",
    "\n",
    "def export_top3_each_condition_one_pdf(\n",
    "    root_path: str,\n",
    "    output_dir: str,\n",
    "    half_box: int = 310,\n",
    "    screen_default: Tuple[int, int] = (1000, 800),\n",
    "    sigma: float = 18.0,\n",
    "    heatmap_alpha: float = 0.70,\n",
    "    heatmap_cmap: str = \"turbo\",\n",
    "    vmax_mode: str = \"p99\",\n",
    ") -> Path:\n",
    "    root = Path(root_path).expanduser().resolve()\n",
    "    out_dir = Path(output_dir).expanduser().resolve()\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    json_path = _find_testing_json(root)\n",
    "    data = json.loads(json_path.read_text(encoding=\"utf-8\"))\n",
    "    if not isinstance(data, list):\n",
    "        raise ValueError(\"❌ testing.json must be a list of objects.\")\n",
    "\n",
    "    all_trials = list(_iter_trials(data))\n",
    "    agg = _aggregate_accuracy(all_trials)\n",
    "    ranked = _rank_most_correct(agg)\n",
    "    ranked.to_csv(out_dir / \"accuracy_by_pair_condition.csv\", index=False)\n",
    "\n",
    "    out_pdf = out_dir / \"TOP3_EACH_VC_SECOND_IMAGE_OVERLAY.pdf\"\n",
    "\n",
    "    with PdfPages(out_pdf) as pdf:\n",
    "        for cond in CONDITIONS:\n",
    "            sub = ranked[ranked[\"condition\"] == cond].sort_values(\n",
    "                [\"acc\", \"pair\"], ascending=[False, True]\n",
    "            ).head(3)\n",
    "\n",
    "            fig, axes = plt.subplots(1, 3, figsize=(18, 6), constrained_layout=True)\n",
    "            last_hm = None\n",
    "\n",
    "            for j, (_, row) in enumerate(sub.iterrows()):\n",
    "                ax = axes[j]\n",
    "\n",
    "                pair_str = str(row[\"pair\"])\n",
    "                trials = _collect_trials(all_trials, cond, pair_str)\n",
    "                if not trials:\n",
    "                    ax.axis(\"off\")\n",
    "                    continue\n",
    "\n",
    "                img_path = _find_image_file(root, trials[0].second_image)\n",
    "                if img_path is None:\n",
    "                    ax.set_title(f\"{cond.upper()} • missing second image\", fontsize=10)\n",
    "                    ax.axis(\"off\")\n",
    "                    continue\n",
    "\n",
    "                sw, sh = screen_default\n",
    "                for t in trials[:3]:\n",
    "                    sw, sh = _screen_dims(t.raw, (sw, sh))\n",
    "\n",
    "                l, ttop, r, b = _image_box_extent(sw, sh, half_box=half_box)\n",
    "                box_size = int(half_box * 2)\n",
    "\n",
    "                img_arr = _load_image_resized(img_path, size_px=box_size)\n",
    "\n",
    "                pts = np.vstack([_extract_fixations(t.raw) for t in trials])\n",
    "                heat = _fdm_in_box(pts, l=l, t=ttop, r=r, b=b, size_px=box_size, sigma=sigma)\n",
    "\n",
    "                acc = float(row[\"acc\"])\n",
    "                right = int(row[\"right\"])\n",
    "                wrong = int(row[\"wrong\"])\n",
    "                N = int(row[\"N\"])\n",
    "                pair_rank = int(row[\"pair_rank_correct\"])\n",
    "                n_pairs = int(row[\"n_pairs\"])\n",
    "\n",
    "                correctness_label = \"Correct\" if acc >= 0.5 else \"Incorrect\"\n",
    "\n",
    "                title1 = f\"Testing • Acc: {acc*100:.1f}% • Pair {pair_rank}/{n_pairs} • {correctness_label}\"\n",
    "                title2 = f\"Subjects: right={right} • wrong={wrong} • N={N} subjects • Second: {len(pts)} fix\"\n",
    "\n",
    "                last_hm = _plot_overlay(\n",
    "                    ax=ax,\n",
    "                    img_arr=img_arr,\n",
    "                    pts=pts,\n",
    "                    heat=heat,\n",
    "                    screen_w=sw,\n",
    "                    screen_h=sh,\n",
    "                    extent_ltrb=(l, ttop, r, b),\n",
    "                    title1=title1,\n",
    "                    title2=title2,\n",
    "                    heatmap_cmap=heatmap_cmap,\n",
    "                    heatmap_alpha=heatmap_alpha,\n",
    "                    vmax_mode=vmax_mode,\n",
    "                )\n",
    "\n",
    "            for k in range(len(sub), 3):\n",
    "                axes[k].axis(\"off\")\n",
    "\n",
    "            fig.suptitle(\n",
    "                f\"Testing Phase - {cond.upper()} Viewing Condition\\n\"\n",
    "                f\"Top 3 Trials (High Accuracy)\\n\"\n",
    "                f\"Ordered from Most Correct \\u2192 Least Correct\",\n",
    "                fontsize=14,\n",
    "                fontweight=\"bold\",\n",
    "            )\n",
    "\n",
    "            if last_hm is not None:\n",
    "                cbar = fig.colorbar(last_hm, ax=axes.ravel().tolist(), shrink=0.9, pad=0.02)\n",
    "                cbar.set_label(\"Fixation Density\", rotation=90)\n",
    "\n",
    "            pdf.savefig(fig)\n",
    "            plt.close(fig)\n",
    "\n",
    "    return out_pdf\n",
    "\n",
    "\n",
    "def _running_in_notebook(argv: List[str]) -> bool:\n",
    "    return \"-f\" in argv or \"ipykernel\" in argv[0].lower()\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"One PDF, 3 pages (full/central/peripheral). Each page shows top 3 pairs (most correct->least correct) with titles like your example.\"\n",
    "    )\n",
    "    parser.add_argument(\"--root\", default=\".\", help=\"Folder to search for testing.json and images.\")\n",
    "    parser.add_argument(\"--out\", default=\"plots\", help=\"Output directory.\")\n",
    "    parser.add_argument(\"--half-box\", type=int, default=310)\n",
    "    parser.add_argument(\"--screen-w\", type=int, default=1000)\n",
    "    parser.add_argument(\"--screen-h\", type=int, default=800)\n",
    "    parser.add_argument(\"--sigma\", type=float, default=18.0)\n",
    "    parser.add_argument(\"--heatmap-alpha\", type=float, default=0.70)\n",
    "    parser.add_argument(\"--heatmap-cmap\", default=\"turbo\")\n",
    "    parser.add_argument(\"--vmax-mode\", default=\"p99\", choices=[\"p99\", \"max\"])\n",
    "\n",
    "    argv = sys.argv[1:]\n",
    "    if _running_in_notebook(sys.argv):\n",
    "        args = parser.parse_args([])  # ignore Jupyter argv\n",
    "    else:\n",
    "        args, _unknown = parser.parse_known_args(argv)\n",
    "\n",
    "    out_pdf = export_top3_each_condition_one_pdf(\n",
    "        root_path=args.root,\n",
    "        output_dir=args.out,\n",
    "        half_box=int(args.half_box),\n",
    "        screen_default=(int(args.screen_w), int(args.screen_h)),\n",
    "        sigma=float(args.sigma),\n",
    "        heatmap_alpha=float(args.heatmap_alpha),\n",
    "        heatmap_cmap=str(args.heatmap_cmap),\n",
    "        vmax_mode=str(args.vmax_mode),\n",
    "    )\n",
    "    print(f\"✅ PDF: {out_pdf}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4dd363c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PDF: /Users/daisybuathatseephol/Documents/three_json_output/plots/TOP3_BOTTOM3_EACH_VC_SECOND_IMAGE_OVERLAY.pdf\n"
     ]
    }
   ],
   "source": [
    "# file: scripts/export_top3_bottom3_grid_onepdf.py\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import re\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Iterable, List, Optional, Sequence, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from PIL import Image\n",
    "\n",
    "try:\n",
    "    from scipy.ndimage import gaussian_filter  # type: ignore\n",
    "except Exception:  # pragma: no cover\n",
    "    gaussian_filter = None\n",
    "\n",
    "\n",
    "CONDITIONS: Tuple[str, ...] = (\"full\", \"central\", \"peripheral\")\n",
    "IMAGE_EXTS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\")\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PairKey:\n",
    "    a: str\n",
    "    b: str\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        return f\"{self.a}__{self.b}\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrialRow:\n",
    "    condition: str\n",
    "    pair: PairKey\n",
    "    first_image: str\n",
    "    second_image: str\n",
    "    correct: Optional[bool]\n",
    "    raw: Dict[str, Any]\n",
    "\n",
    "\n",
    "def _normalize_image_name(name: str) -> str:\n",
    "    s = str(name).strip().lower()\n",
    "    s = re.sub(r\"\\.(jpg|jpeg|png|bmp|tif|tiff)$\", \"\", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "def _clean_condition(x: Any) -> Optional[str]:\n",
    "    if x is None:\n",
    "        return None\n",
    "    s = str(x).strip().lower()\n",
    "    return s if s in CONDITIONS else None\n",
    "\n",
    "\n",
    "def _as_bool(x: Any) -> Optional[bool]:\n",
    "    if x is None:\n",
    "        return None\n",
    "    if isinstance(x, bool):\n",
    "        return x\n",
    "    if isinstance(x, (int, np.integer)) and x in (0, 1):\n",
    "        return bool(x)\n",
    "    if isinstance(x, str):\n",
    "        v = x.strip().lower()\n",
    "        if v in (\"true\", \"t\", \"yes\", \"y\", \"correct\", \"right\", \"1\"):\n",
    "            return True\n",
    "        if v in (\"false\", \"f\", \"no\", \"n\", \"incorrect\", \"wrong\", \"0\"):\n",
    "            return False\n",
    "    return None\n",
    "\n",
    "\n",
    "def _normalize_answer(x: Any) -> Optional[str]:\n",
    "    if x is None:\n",
    "        return None\n",
    "    s = str(x).strip().lower()\n",
    "    return s or None\n",
    "\n",
    "\n",
    "def _detect_correct(item: Dict[str, Any]) -> Optional[bool]:\n",
    "    for k in (\"acc\", \"correct\", \"is_correct\", \"response_correct\", \"trial_correct\", \"accuracy\"):\n",
    "        if k in item:\n",
    "            b = _as_bool(item.get(k))\n",
    "            if b is not None:\n",
    "                return b\n",
    "    subj = _normalize_answer(item.get(\"subj_answer\"))\n",
    "    corr = _normalize_answer(item.get(\"correct_response\"))\n",
    "    if subj is not None and corr is not None:\n",
    "        return subj == corr\n",
    "    return None\n",
    "\n",
    "\n",
    "def _find_testing_json(root: Path) -> Path:\n",
    "    hits = list(root.rglob(\"testing.json\"))\n",
    "    if not hits:\n",
    "        raise FileNotFoundError(f\"❌ testing.json not found under: {root}\")\n",
    "    hits.sort(key=lambda p: (len(p.parts), str(p)))\n",
    "    return hits[0]\n",
    "\n",
    "\n",
    "def _find_image_file(root: Path, image_name: str) -> Optional[Path]:\n",
    "    base = _normalize_image_name(image_name)\n",
    "    candidates: List[Path] = []\n",
    "    for p in root.rglob(\"*\"):\n",
    "        if not p.is_file():\n",
    "            continue\n",
    "        if p.suffix.lower() not in IMAGE_EXTS:\n",
    "            continue\n",
    "        if _normalize_image_name(p.name) == base or _normalize_image_name(p.stem) == base:\n",
    "            candidates.append(p)\n",
    "    if not candidates:\n",
    "        return None\n",
    "    candidates.sort(key=lambda p: (len(p.parts), str(p)))\n",
    "    return candidates[0]\n",
    "\n",
    "\n",
    "def _iter_trials(data: Sequence[Dict[str, Any]]) -> Iterable[TrialRow]:\n",
    "    for item in data:\n",
    "        cond = _clean_condition(item.get(\"viewing_condition\") or item.get(\"condition\"))\n",
    "        if cond is None:\n",
    "            continue\n",
    "\n",
    "        first = item.get(\"first_image\")\n",
    "        second = item.get(\"second_image\")\n",
    "        if not first or not second:\n",
    "            continue\n",
    "\n",
    "        first_s = str(first).strip()\n",
    "        second_s = str(second).strip()\n",
    "\n",
    "        a = _normalize_image_name(first_s)\n",
    "        b = _normalize_image_name(second_s)\n",
    "        pair = PairKey(*sorted((a, b)))\n",
    "\n",
    "        yield TrialRow(\n",
    "            condition=cond,\n",
    "            pair=pair,\n",
    "            first_image=first_s,\n",
    "            second_image=second_s,\n",
    "            correct=_detect_correct(item),\n",
    "            raw=item,\n",
    "        )\n",
    "\n",
    "\n",
    "def _extract_fixations(item: Dict[str, Any]) -> np.ndarray:\n",
    "    xs = item.get(\"fix_x\")\n",
    "    ys = item.get(\"fix_y\")\n",
    "    if not isinstance(xs, (list, tuple)) or not isinstance(ys, (list, tuple)):\n",
    "        return np.zeros((0, 2), dtype=float)\n",
    "    if len(xs) != len(ys) or len(xs) == 0:\n",
    "        return np.zeros((0, 2), dtype=float)\n",
    "    try:\n",
    "        arr = np.column_stack([np.asarray(xs, dtype=float), np.asarray(ys, dtype=float)])\n",
    "        arr = arr[np.isfinite(arr).all(axis=1)]\n",
    "        return arr\n",
    "    except Exception:\n",
    "        return np.zeros((0, 2), dtype=float)\n",
    "\n",
    "\n",
    "def _screen_dims(item: Dict[str, Any], default: Tuple[int, int]) -> Tuple[int, int]:\n",
    "    for kw, kh in (\n",
    "        (\"screen_width\", \"screen_height\"),\n",
    "        (\"window_width\", \"window_height\"),\n",
    "        (\"display_width\", \"display_height\"),\n",
    "        (\"screenW\", \"screenH\"),\n",
    "    ):\n",
    "        if kw in item and kh in item:\n",
    "            try:\n",
    "                w = int(float(item[kw]))\n",
    "                h = int(float(item[kh]))\n",
    "                if w > 0 and h > 0:\n",
    "                    return w, h\n",
    "            except Exception:\n",
    "                pass\n",
    "    return default\n",
    "\n",
    "\n",
    "def _image_box_extent(screen_w: int, screen_h: int, half_box: int) -> Tuple[int, int, int, int]:\n",
    "    l = screen_w // 2 - half_box\n",
    "    t = screen_h // 2 - half_box\n",
    "    r = screen_w // 2 + half_box\n",
    "    b = screen_h // 2 + half_box\n",
    "    return l, t, r, b\n",
    "\n",
    "\n",
    "def _load_image_resized(path: Path, size_px: int) -> np.ndarray:\n",
    "    img = Image.open(path).convert(\"L\")\n",
    "    img = img.resize((size_px, size_px), resample=Image.BICUBIC)\n",
    "    return np.asarray(img)\n",
    "\n",
    "\n",
    "def _fdm_in_box(\n",
    "    pts: np.ndarray,\n",
    "    l: int,\n",
    "    t: int,\n",
    "    r: int,\n",
    "    b: int,\n",
    "    size_px: int,\n",
    "    sigma: float,\n",
    ") -> np.ndarray:\n",
    "    if len(pts) == 0:\n",
    "        return np.zeros((size_px, size_px), dtype=float)\n",
    "\n",
    "    in_box = (pts[:, 0] >= l) & (pts[:, 0] <= r) & (pts[:, 1] >= t) & (pts[:, 1] <= b)\n",
    "    p = pts[in_box]\n",
    "    if len(p) == 0:\n",
    "        return np.zeros((size_px, size_px), dtype=float)\n",
    "\n",
    "    x = (p[:, 0] - l) / max(1e-9, (r - l)) * (size_px - 1)\n",
    "    y = (p[:, 1] - t) / max(1e-9, (b - t)) * (size_px - 1)\n",
    "    x = np.clip(x, 0, size_px - 1)\n",
    "    y = np.clip(y, 0, size_px - 1)\n",
    "\n",
    "    heat, _, _ = np.histogram2d(y, x, bins=[size_px, size_px], range=[[0, size_px], [0, size_px]])\n",
    "    heat = heat.astype(float)\n",
    "\n",
    "    if gaussian_filter is not None:\n",
    "        heat = gaussian_filter(heat, sigma=sigma)\n",
    "    else:\n",
    "        k = int(max(3, math.ceil(sigma * 3)) * 2 + 1)\n",
    "        ax = np.arange(k) - k // 2\n",
    "        kernel = np.exp(-(ax**2) / (2 * sigma**2))\n",
    "        kernel /= kernel.sum()\n",
    "        heat = np.apply_along_axis(lambda m: np.convolve(m, kernel, mode=\"same\"), axis=0, arr=heat)\n",
    "        heat = np.apply_along_axis(lambda m: np.convolve(m, kernel, mode=\"same\"), axis=1, arr=heat)\n",
    "\n",
    "    s = heat.sum()\n",
    "    if s > 0:\n",
    "        heat /= s\n",
    "    return heat\n",
    "\n",
    "\n",
    "def _aggregate_accuracy(trials: Sequence[TrialRow]) -> pd.DataFrame:\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "    for t in trials:\n",
    "        if t.correct is None:\n",
    "            continue\n",
    "        rows.append({\"condition\": t.condition, \"pair\": t.pair.as_str, \"correct\": int(bool(t.correct))})\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        raise ValueError(\"❌ No correctness detected (acc / subj_answer vs correct_response).\")\n",
    "\n",
    "    return (\n",
    "        df.groupby([\"condition\", \"pair\"], as_index=False)\n",
    "        .agg(N=(\"correct\", \"size\"), right=(\"correct\", \"sum\"))\n",
    "        .assign(wrong=lambda x: x[\"N\"] - x[\"right\"])\n",
    "        .assign(acc=lambda x: x[\"right\"] / x[\"N\"])\n",
    "    )\n",
    "\n",
    "\n",
    "def _plot_overlay(\n",
    "    ax: plt.Axes,\n",
    "    img_arr: np.ndarray,\n",
    "    pts: np.ndarray,\n",
    "    heat: np.ndarray,\n",
    "    screen_w: int,\n",
    "    screen_h: int,\n",
    "    extent_ltrb: Tuple[int, int, int, int],  # (l,t,r,b)\n",
    "    title1: str,\n",
    "    title2: str,\n",
    "    heatmap_cmap: str,\n",
    "    heatmap_alpha: float,\n",
    "    vmax_mode: str,\n",
    ") -> Any:\n",
    "    l, t, r, b = extent_ltrb\n",
    "    ax.imshow(img_arr, cmap=\"gray\", origin=\"upper\", extent=(l, r, b, t))\n",
    "\n",
    "    if vmax_mode == \"p99\":\n",
    "        vmax = float(np.quantile(heat, 0.99)) if heat.max() > 0 else 1.0\n",
    "    else:\n",
    "        vmax = float(heat.max()) if heat.max() > 0 else 1.0\n",
    "\n",
    "    hm = ax.imshow(\n",
    "        heat,\n",
    "        origin=\"upper\",\n",
    "        extent=(l, r, b, t),\n",
    "        cmap=heatmap_cmap,\n",
    "        alpha=heatmap_alpha,\n",
    "        vmin=0.0,\n",
    "        vmax=vmax,\n",
    "    )\n",
    "\n",
    "    if len(pts) > 0:\n",
    "        ax.scatter(\n",
    "            pts[:, 0],\n",
    "            pts[:, 1],\n",
    "            s=30,\n",
    "            facecolors=(1.0, 0.42, 0.42, 0.50),\n",
    "            edgecolors=(1.0, 1.0, 1.0, 0.80),\n",
    "            linewidths=0.8,\n",
    "        )\n",
    "\n",
    "    ax.set_xlim(0, screen_w)\n",
    "    ax.set_ylim(screen_h, 0)\n",
    "    ax.set_xlabel(\"x (screen px)\")\n",
    "    ax.set_ylabel(\"y (screen px)\")\n",
    "    ax.set_title(f\"{title1}\\n{title2}\", fontsize=10)\n",
    "    ax.grid(False)\n",
    "    return hm\n",
    "\n",
    "\n",
    "def export_top_bottom_3_one_pdf(\n",
    "    root_path: str,\n",
    "    output_dir: str,\n",
    "    half_box: int = 310,\n",
    "    screen_default: Tuple[int, int] = (1000, 800),\n",
    "    sigma: float = 18.0,\n",
    "    heatmap_alpha: float = 0.70,\n",
    "    heatmap_cmap: str = \"turbo\",\n",
    "    vmax_mode: str = \"p99\",\n",
    ") -> Path:\n",
    "    root = Path(root_path).expanduser().resolve()\n",
    "    out_dir = Path(output_dir).expanduser().resolve()\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    json_path = _find_testing_json(root)\n",
    "    data = json.loads(json_path.read_text(encoding=\"utf-8\"))\n",
    "    if not isinstance(data, list):\n",
    "        raise ValueError(\"❌ testing.json must be a list of objects.\")\n",
    "\n",
    "    all_trials = list(_iter_trials(data))\n",
    "    agg = _aggregate_accuracy(all_trials)\n",
    "    agg.to_csv(out_dir / \"accuracy_by_pair_condition.csv\", index=False)\n",
    "\n",
    "    out_pdf = out_dir / \"TOP3_BOTTOM3_EACH_VC_SECOND_IMAGE_OVERLAY.pdf\"\n",
    "\n",
    "    with PdfPages(out_pdf) as pdf:\n",
    "        for cond in CONDITIONS:\n",
    "            cond_agg = agg[agg[\"condition\"] == cond].copy()\n",
    "            cond_agg = cond_agg.sort_values([\"acc\", \"pair\"], ascending=[True, True]).reset_index(drop=True)\n",
    "            n_pairs = len(cond_agg)\n",
    "\n",
    "            bottom3 = cond_agg.head(3).copy()\n",
    "            top3 = cond_agg.tail(3).sort_values([\"acc\", \"pair\"], ascending=[False, True]).copy()\n",
    "\n",
    "            fig, axes = plt.subplots(2, 3, figsize=(18, 10), constrained_layout=True)\n",
    "            last_hm = None\n",
    "\n",
    "            def render_row(row_df: pd.DataFrame, row_idx: int, label: str, rank_base: str) -> None:\n",
    "                nonlocal last_hm\n",
    "                for j in range(3):\n",
    "                    ax = axes[row_idx, j]\n",
    "                    if j >= len(row_df):\n",
    "                        ax.axis(\"off\")\n",
    "                        continue\n",
    "\n",
    "                    row = row_df.iloc[j]\n",
    "                    pair_str = str(row[\"pair\"])\n",
    "                    trials = [t for t in all_trials if t.condition == cond and t.pair.as_str == pair_str]\n",
    "                    if not trials:\n",
    "                        ax.axis(\"off\")\n",
    "                        continue\n",
    "\n",
    "                    img_path = _find_image_file(root, trials[0].second_image)\n",
    "                    if img_path is None:\n",
    "                        ax.set_title(f\"{cond.upper()} • missing second image\", fontsize=10)\n",
    "                        ax.axis(\"off\")\n",
    "                        continue\n",
    "\n",
    "                    sw, sh = screen_default\n",
    "                    for t in trials[:3]:\n",
    "                        sw, sh = _screen_dims(t.raw, (sw, sh))\n",
    "\n",
    "                    l, ttop, r, b = _image_box_extent(sw, sh, half_box=half_box)\n",
    "                    box_size = int(half_box * 2)\n",
    "                    img_arr = _load_image_resized(img_path, size_px=box_size)\n",
    "\n",
    "                    pts = np.vstack([_extract_fixations(t.raw) for t in trials])\n",
    "                    heat = _fdm_in_box(pts, l=l, t=ttop, r=r, b=b, size_px=box_size, sigma=sigma)\n",
    "\n",
    "                    acc = float(row[\"acc\"])\n",
    "                    right = int(row[\"right\"])\n",
    "                    wrong = int(row[\"wrong\"])\n",
    "                    N = int(row[\"N\"])\n",
    "\n",
    "                    # Pair rank: mimic your existing PDFs:\n",
    "                    # - top row: 1/24, 2/24, 3/24 ...\n",
    "                    # - bottom row: 1/24, 2/24, 3/24 ... (most incorrect -> least incorrect)\n",
    "                    # If you want global rank within all pairs, swap this logic.\n",
    "                    if rank_base == \"top\":\n",
    "                        pair_rank = j + 1\n",
    "                    else:\n",
    "                        pair_rank = j + 1\n",
    "\n",
    "                    correctness_label = \"Correct\" if acc >= 0.5 else \"Incorrect\"\n",
    "                    title1 = f\"Testing • Acc: {acc*100:.1f}% • Pair {pair_rank}/{n_pairs} • {correctness_label}\"\n",
    "                    title2 = f\"Subjects: right={right} • wrong={wrong} • N={N} subjects • Second: {len(pts)} fix\"\n",
    "\n",
    "                    last_hm = _plot_overlay(\n",
    "                        ax=ax,\n",
    "                        img_arr=img_arr,\n",
    "                        pts=pts,\n",
    "                        heat=heat,\n",
    "                        screen_w=sw,\n",
    "                        screen_h=sh,\n",
    "                        extent_ltrb=(l, ttop, r, b),\n",
    "                        title1=title1,\n",
    "                        title2=title2,\n",
    "                        heatmap_cmap=heatmap_cmap,\n",
    "                        heatmap_alpha=heatmap_alpha,\n",
    "                        vmax_mode=vmax_mode,\n",
    "                    )\n",
    "                    ax.text(\n",
    "                        0.01,\n",
    "                        0.99,\n",
    "                        label,\n",
    "                        transform=ax.transAxes,\n",
    "                        va=\"top\",\n",
    "                        ha=\"left\",\n",
    "                        fontsize=10,\n",
    "                        fontweight=\"bold\",\n",
    "                        bbox=dict(boxstyle=\"round,pad=0.2\", fc=\"white\", ec=\"none\", alpha=0.7),\n",
    "                    )\n",
    "\n",
    "            # Top row: Top 3 (most correct -> least correct)\n",
    "            render_row(top3.reset_index(drop=True), row_idx=0, label=\"TOP\", rank_base=\"top\")\n",
    "            # Bottom row: Bottom 3 (most incorrect -> least incorrect)\n",
    "            render_row(bottom3.reset_index(drop=True), row_idx=1, label=\"BOTTOM\", rank_base=\"bottom\")\n",
    "\n",
    "            fig.suptitle(\n",
    "                f\"Testing Phase - {cond.upper()} Viewing Condition\\n\"\n",
    "                f\"Top 3 (High Accuracy) + Bottom 3 (Low Accuracy)\\n\"\n",
    "                f\"Top: Most Correct \\u2192 Least Correct   |   Bottom: Most Incorrect \\u2192 Least Incorrect\",\n",
    "                fontsize=14,\n",
    "                fontweight=\"bold\",\n",
    "            )\n",
    "\n",
    "            if last_hm is not None:\n",
    "                cbar = fig.colorbar(last_hm, ax=axes.ravel().tolist(), shrink=0.85, pad=0.02)\n",
    "                cbar.set_label(\"Fixation Density\", rotation=90)\n",
    "\n",
    "            pdf.savefig(fig)\n",
    "            plt.close(fig)\n",
    "\n",
    "    return out_pdf\n",
    "\n",
    "\n",
    "def _running_in_notebook(argv: List[str]) -> bool:\n",
    "    return \"-f\" in argv or \"ipykernel\" in argv[0].lower()\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"One PDF (3 pages): per viewing condition, one figure with 6 panels (Top 3 + Bottom 3).\"\n",
    "    )\n",
    "    parser.add_argument(\"--root\", default=\".\", help=\"Folder to search for testing.json and images.\")\n",
    "    parser.add_argument(\"--out\", default=\"plots\", help=\"Output directory.\")\n",
    "    parser.add_argument(\"--half-box\", type=int, default=310)\n",
    "    parser.add_argument(\"--screen-w\", type=int, default=1000)\n",
    "    parser.add_argument(\"--screen-h\", type=int, default=800)\n",
    "    parser.add_argument(\"--sigma\", type=float, default=18.0)\n",
    "    parser.add_argument(\"--heatmap-alpha\", type=float, default=0.70)\n",
    "    parser.add_argument(\"--heatmap-cmap\", default=\"turbo\")\n",
    "    parser.add_argument(\"--vmax-mode\", default=\"p99\", choices=[\"p99\", \"max\"])\n",
    "\n",
    "    argv = sys.argv[1:]\n",
    "    if _running_in_notebook(sys.argv):\n",
    "        args = parser.parse_args([])  # ignore Jupyter argv\n",
    "    else:\n",
    "        args, _unknown = parser.parse_known_args(argv)\n",
    "\n",
    "    out_pdf = export_top_bottom_3_one_pdf(\n",
    "        root_path=args.root,\n",
    "        output_dir=args.out,\n",
    "        half_box=int(args.half_box),\n",
    "        screen_default=(int(args.screen_w), int(args.screen_h)),\n",
    "        sigma=float(args.sigma),\n",
    "        heatmap_alpha=float(args.heatmap_alpha),\n",
    "        heatmap_cmap=str(args.heatmap_cmap),\n",
    "        vmax_mode=str(args.vmax_mode),\n",
    "    )\n",
    "    print(f\"✅ PDF: {out_pdf}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e72d45ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SANITY CHECK REPORT\n",
      "================================================================================\n",
      "JSON: /Users/daisybuathatseephol/Documents/three_json_output/Testing/testing.json\n",
      "Total rows: 2304\n",
      "Valid rows parsed: 2304\n",
      "Rows with any issues: 1\n",
      "\n",
      "Rows by condition:\n",
      "  full: 768\n",
      "  central: 768\n",
      "  peripheral: 768\n",
      "\n",
      "Unique pairs by condition:\n",
      "  full: 24\n",
      "  central: 24\n",
      "  peripheral: 24\n",
      "\n",
      "Pair overlap (should usually be 0 across conditions):\n",
      "  full ∩ central: 0\n",
      "  full ∩ peripheral: 0\n",
      "  central ∩ peripheral: 0\n",
      "  all three: 0\n",
      "\n",
      "Issues by type:\n",
      "  acc_mismatch_subj_vs_correct: 1\n",
      "\n",
      "Saved to: /Users/daisybuathatseephol/Documents/three_json_output/sanity_check_out\n",
      "  - sanity_report.json\n",
      "  - rows_normalized.csv\n",
      "  - pair_summary.csv\n",
      "  - pair_id_map.csv\n",
      "  - row_issues.csv\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# file: scripts/sanity_check_testing_json.py\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Sequence, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "CONDITIONS = (\"full\", \"central\", \"peripheral\")\n",
    "IMAGE_EXTS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\")\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PairKey:\n",
    "    a: str\n",
    "    b: str\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        return f\"{self.a}__{self.b}\"\n",
    "\n",
    "\n",
    "def _norm(s: Any) -> str:\n",
    "    return str(s).strip().lower()\n",
    "\n",
    "\n",
    "def _normalize_image_name(name: Any) -> str:\n",
    "    s = _norm(name)\n",
    "    s = re.sub(r\"\\.(jpg|jpeg|png|bmp|tif|tiff)$\", \"\", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "def _clean_condition(x: Any) -> Optional[str]:\n",
    "    if x is None:\n",
    "        return None\n",
    "    s = _norm(x)\n",
    "    return s if s in CONDITIONS else None\n",
    "\n",
    "\n",
    "def _as_bool(x: Any) -> Optional[bool]:\n",
    "    if x is None:\n",
    "        return None\n",
    "    if isinstance(x, bool):\n",
    "        return x\n",
    "    if isinstance(x, int) and x in (0, 1):\n",
    "        return bool(x)\n",
    "    if isinstance(x, str):\n",
    "        v = _norm(x)\n",
    "        if v in (\"true\", \"t\", \"yes\", \"y\", \"correct\", \"right\", \"1\"):\n",
    "            return True\n",
    "        if v in (\"false\", \"f\", \"no\", \"n\", \"incorrect\", \"wrong\", \"0\"):\n",
    "            return False\n",
    "    return None\n",
    "\n",
    "\n",
    "def _normalize_answer(x: Any) -> Optional[str]:\n",
    "    if x is None:\n",
    "        return None\n",
    "    s = _norm(x)\n",
    "    return s or None\n",
    "\n",
    "\n",
    "def _detect_correct(item: Dict[str, Any]) -> Tuple[Optional[bool], Optional[bool]]:\n",
    "    \"\"\"\n",
    "    Returns: (correct_inferred, correct_from_acc_field)\n",
    "    - correct_from_acc_field is only from acc-like boolean field if present\n",
    "    - correct_inferred uses acc if available else subj_answer==correct_response if available\n",
    "    \"\"\"\n",
    "    acc_field = None\n",
    "    for k in (\"acc\", \"correct\", \"is_correct\", \"response_correct\", \"trial_correct\", \"accuracy\"):\n",
    "        if k in item:\n",
    "            acc_field = _as_bool(item.get(k))\n",
    "            break\n",
    "\n",
    "    subj = _normalize_answer(item.get(\"subj_answer\"))\n",
    "    corr = _normalize_answer(item.get(\"correct_response\"))\n",
    "    from_answers = (subj == corr) if (subj is not None and corr is not None) else None\n",
    "\n",
    "    inferred = acc_field if acc_field is not None else from_answers\n",
    "    return inferred, acc_field\n",
    "\n",
    "\n",
    "def _extract_fixations(item: Dict[str, Any]) -> Tuple[List[float], List[float]]:\n",
    "    xs = item.get(\"fix_x\")\n",
    "    ys = item.get(\"fix_y\")\n",
    "    if not isinstance(xs, list) or not isinstance(ys, list):\n",
    "        return [], []\n",
    "    return xs, ys\n",
    "\n",
    "\n",
    "def _finite_float_list(xs: Sequence[Any]) -> Tuple[bool, List[float]]:\n",
    "    out: List[float] = []\n",
    "    try:\n",
    "        for v in xs:\n",
    "            f = float(v)\n",
    "            if not math.isfinite(f):\n",
    "                return False, []\n",
    "            out.append(f)\n",
    "        return True, out\n",
    "    except Exception:\n",
    "        return False, []\n",
    "\n",
    "\n",
    "def _find_testing_json(root: Path) -> Path:\n",
    "    hits = list(root.rglob(\"testing.json\"))\n",
    "    if not hits:\n",
    "        raise FileNotFoundError(f\"testing.json not found under {root}\")\n",
    "    hits.sort(key=lambda p: (len(p.parts), str(p)))\n",
    "    return hits[0]\n",
    "\n",
    "\n",
    "def _maybe_find_image(root: Path, image_name: str) -> bool:\n",
    "    base = _normalize_image_name(image_name)\n",
    "    # quick heuristic: if exact filename exists anywhere, ok\n",
    "    for ext in IMAGE_EXTS:\n",
    "        if list(root.rglob(base + ext)):\n",
    "            return True\n",
    "    # otherwise look for any file with same stem\n",
    "    for p in root.rglob(\"*\"):\n",
    "        if p.is_file() and p.suffix.lower() in IMAGE_EXTS:\n",
    "            if _normalize_image_name(p.name) == base or _normalize_image_name(p.stem) == base:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def sanity_check(\n",
    "    root: str,\n",
    "    json_path: Optional[str],\n",
    "    out_dir: str,\n",
    "    check_images: bool = False,\n",
    ") -> Path:\n",
    "    root_p = Path(root).expanduser().resolve()\n",
    "    out_p = Path(out_dir).expanduser().resolve()\n",
    "    out_p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if json_path:\n",
    "        jp = Path(json_path).expanduser().resolve()\n",
    "        if not jp.exists():\n",
    "            raise FileNotFoundError(f\"--json not found: {jp}\")\n",
    "    else:\n",
    "        jp = _find_testing_json(root_p)\n",
    "\n",
    "    raw = json.loads(jp.read_text(encoding=\"utf-8\"))\n",
    "    if not isinstance(raw, list):\n",
    "        raise ValueError(\"testing.json must be a list of dicts\")\n",
    "    if not raw or not all(isinstance(x, dict) for x in raw):\n",
    "        raise ValueError(\"testing.json must be a non-empty list of objects\")\n",
    "\n",
    "    issues: List[Dict[str, Any]] = []\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "\n",
    "    pair_first_seen_idx: Dict[str, Dict[str, int]] = {c: {} for c in CONDITIONS}\n",
    "    pair_id_map: Dict[str, Dict[str, int]] = {c: {} for c in CONDITIONS}\n",
    "    pair_id_counter: Dict[str, int] = {c: 0 for c in CONDITIONS}\n",
    "\n",
    "    required_keys = (\"viewing_condition\", \"first_image\", \"second_image\")\n",
    "\n",
    "    for idx, item in enumerate(raw):\n",
    "        cond = _clean_condition(item.get(\"viewing_condition\") or item.get(\"condition\"))\n",
    "        first_img = item.get(\"first_image\")\n",
    "        second_img = item.get(\"second_image\")\n",
    "        subj_id = item.get(\"subject_id\")\n",
    "        trial_index = item.get(\"trial_index\")\n",
    "\n",
    "        missing = [k for k in required_keys if item.get(k) in (None, \"\", [])]\n",
    "        if missing:\n",
    "            issues.append(\n",
    "                {\n",
    "                    \"row_index\": idx,\n",
    "                    \"type\": \"missing_required_keys\",\n",
    "                    \"missing_keys\": \",\".join(missing),\n",
    "                    \"condition\": item.get(\"viewing_condition\"),\n",
    "                }\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        if cond is None:\n",
    "            issues.append(\n",
    "                {\n",
    "                    \"row_index\": idx,\n",
    "                    \"type\": \"invalid_condition\",\n",
    "                    \"value\": item.get(\"viewing_condition\"),\n",
    "                }\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        a = _normalize_image_name(first_img)\n",
    "        b = _normalize_image_name(second_img)\n",
    "        pair = PairKey(*sorted((a, b))).as_str\n",
    "\n",
    "        # pair_id per condition by first appearance in JSON order\n",
    "        if pair not in pair_id_map[cond]:\n",
    "            pair_id_counter[cond] += 1\n",
    "            pair_id_map[cond][pair] = pair_id_counter[cond]\n",
    "            pair_first_seen_idx[cond][pair] = idx\n",
    "\n",
    "        correct_inferred, correct_from_acc = _detect_correct(item)\n",
    "\n",
    "        # fix arrays checks\n",
    "        fix_x_raw, fix_y_raw = _extract_fixations(item)\n",
    "        if bool(fix_x_raw) != bool(fix_y_raw):\n",
    "            issues.append(\n",
    "                {\n",
    "                    \"row_index\": idx,\n",
    "                    \"type\": \"fix_arrays_missing_one_side\",\n",
    "                    \"condition\": cond,\n",
    "                    \"pair\": pair,\n",
    "                    \"has_fix_x\": isinstance(item.get(\"fix_x\"), list),\n",
    "                    \"has_fix_y\": isinstance(item.get(\"fix_y\"), list),\n",
    "                }\n",
    "            )\n",
    "\n",
    "        ok_x, fix_x = _finite_float_list(fix_x_raw) if fix_x_raw else (True, [])\n",
    "        ok_y, fix_y = _finite_float_list(fix_y_raw) if fix_y_raw else (True, [])\n",
    "        if not ok_x or not ok_y:\n",
    "            issues.append(\n",
    "                {\n",
    "                    \"row_index\": idx,\n",
    "                    \"type\": \"fix_arrays_non_numeric_or_non_finite\",\n",
    "                    \"condition\": cond,\n",
    "                    \"pair\": pair,\n",
    "                }\n",
    "            )\n",
    "        if len(fix_x) != len(fix_y):\n",
    "            issues.append(\n",
    "                {\n",
    "                    \"row_index\": idx,\n",
    "                    \"type\": \"fix_arrays_length_mismatch\",\n",
    "                    \"condition\": cond,\n",
    "                    \"pair\": pair,\n",
    "                    \"len_x\": len(fix_x),\n",
    "                    \"len_y\": len(fix_y),\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # acc vs answers consistency\n",
    "        subj = _normalize_answer(item.get(\"subj_answer\"))\n",
    "        corr = _normalize_answer(item.get(\"correct_response\"))\n",
    "        if correct_from_acc is not None and subj is not None and corr is not None:\n",
    "            from_answers = subj == corr\n",
    "            if from_answers != correct_from_acc:\n",
    "                issues.append(\n",
    "                    {\n",
    "                        \"row_index\": idx,\n",
    "                        \"type\": \"acc_mismatch_subj_vs_correct\",\n",
    "                        \"condition\": cond,\n",
    "                        \"pair\": pair,\n",
    "                        \"acc_field\": correct_from_acc,\n",
    "                        \"subj_answer\": subj,\n",
    "                        \"correct_response\": corr,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        # optional image existence\n",
    "        img_ok = None\n",
    "        if check_images:\n",
    "            img_ok = bool(_maybe_find_image(root_p, str(second_img)))\n",
    "\n",
    "            if not img_ok:\n",
    "                issues.append(\n",
    "                    {\n",
    "                        \"row_index\": idx,\n",
    "                        \"type\": \"missing_image_file_second_image\",\n",
    "                        \"condition\": cond,\n",
    "                        \"pair\": pair,\n",
    "                        \"second_image\": str(second_img),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        rows.append(\n",
    "            {\n",
    "                \"row_index\": idx,\n",
    "                \"condition\": cond,\n",
    "                \"pair\": pair,\n",
    "                \"pair_id\": pair_id_map[cond][pair],\n",
    "                \"pair_first_seen_row\": pair_first_seen_idx[cond][pair],\n",
    "                \"subject_id\": subj_id,\n",
    "                \"trial_index\": trial_index,\n",
    "                \"first_image\": str(first_img),\n",
    "                \"second_image\": str(second_img),\n",
    "                \"correct\": correct_inferred,\n",
    "                \"correct_from_acc\": correct_from_acc,\n",
    "                \"n_fix\": min(len(fix_x), len(fix_y)),\n",
    "                \"image_ok_second\": img_ok,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    issues_df = pd.DataFrame(issues)\n",
    "\n",
    "    # aggregates\n",
    "    summary: Dict[str, Any] = {}\n",
    "    summary[\"json_path\"] = str(jp)\n",
    "    summary[\"n_rows_total\"] = len(raw)\n",
    "    summary[\"n_rows_valid\"] = len(df)\n",
    "    summary[\"n_rows_with_issues\"] = int(issues_df[\"row_index\"].nunique()) if not issues_df.empty else 0\n",
    "    summary[\"issues_by_type\"] = (\n",
    "        issues_df[\"type\"].value_counts().to_dict() if not issues_df.empty else {}\n",
    "    )\n",
    "\n",
    "    cond_counts = df[\"condition\"].value_counts().to_dict()\n",
    "    summary[\"rows_by_condition\"] = {c: int(cond_counts.get(c, 0)) for c in CONDITIONS}\n",
    "\n",
    "    # pair summary\n",
    "    pair_summary = (\n",
    "        df.groupby([\"condition\", \"pair\", \"pair_id\"], as_index=False)\n",
    "        .agg(\n",
    "            n_trials=(\"row_index\", \"size\"),\n",
    "            n_subjects=(\"subject_id\", lambda s: s.nunique(dropna=True)),\n",
    "            right=(\"correct\", lambda s: int(pd.Series(s).dropna().sum()) if len(pd.Series(s).dropna()) else 0),\n",
    "            n_correct_known=(\"correct\", lambda s: int(pd.Series(s).dropna().shape[0])),\n",
    "            first_seen=(\"pair_first_seen_row\", \"min\"),\n",
    "        )\n",
    "    )\n",
    "    pair_summary[\"wrong\"] = pair_summary[\"n_correct_known\"] - pair_summary[\"right\"]\n",
    "    pair_summary[\"acc\"] = pair_summary.apply(\n",
    "        lambda r: (r[\"right\"] / r[\"n_correct_known\"]) if r[\"n_correct_known\"] else float(\"nan\"), axis=1\n",
    "    )\n",
    "\n",
    "    summary[\"unique_pairs_by_condition\"] = {\n",
    "        c: int(pair_summary[pair_summary[\"condition\"] == c][\"pair\"].nunique()) for c in CONDITIONS\n",
    "    }\n",
    "\n",
    "    # cross-condition overlap\n",
    "    pairs_by_cond = {\n",
    "        c: set(pair_summary[pair_summary[\"condition\"] == c][\"pair\"].tolist()) for c in CONDITIONS\n",
    "    }\n",
    "    summary[\"pair_overlap_full_central\"] = len(pairs_by_cond[\"full\"] & pairs_by_cond[\"central\"])\n",
    "    summary[\"pair_overlap_full_peripheral\"] = len(pairs_by_cond[\"full\"] & pairs_by_cond[\"peripheral\"])\n",
    "    summary[\"pair_overlap_central_peripheral\"] = len(pairs_by_cond[\"central\"] & pairs_by_cond[\"peripheral\"])\n",
    "    summary[\"pair_overlap_all_three\"] = len(\n",
    "        pairs_by_cond[\"full\"] & pairs_by_cond[\"central\"] & pairs_by_cond[\"peripheral\"]\n",
    "    )\n",
    "\n",
    "    # pair id map output\n",
    "    pid_rows: List[Dict[str, Any]] = []\n",
    "    for c in CONDITIONS:\n",
    "        for pair, pid in pair_id_map[c].items():\n",
    "            pid_rows.append(\n",
    "                {\n",
    "                    \"condition\": c,\n",
    "                    \"pair\": pair,\n",
    "                    \"pair_id\": pid,\n",
    "                    \"first_seen_row\": pair_first_seen_idx[c][pair],\n",
    "                }\n",
    "            )\n",
    "    pair_id_df = pd.DataFrame(pid_rows).sort_values([\"condition\", \"pair_id\"])\n",
    "\n",
    "    # save artifacts\n",
    "    (out_p / \"sanity_report.json\").write_text(json.dumps(summary, indent=2), encoding=\"utf-8\")\n",
    "    df.to_csv(out_p / \"rows_normalized.csv\", index=False)\n",
    "    pair_summary.to_csv(out_p / \"pair_summary.csv\", index=False)\n",
    "    pair_id_df.to_csv(out_p / \"pair_id_map.csv\", index=False)\n",
    "    if not issues_df.empty:\n",
    "        issues_df.to_csv(out_p / \"row_issues.csv\", index=False)\n",
    "\n",
    "    # console report\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"SANITY CHECK REPORT\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"JSON: {jp}\")\n",
    "    print(f\"Total rows: {summary['n_rows_total']}\")\n",
    "    print(f\"Valid rows parsed: {summary['n_rows_valid']}\")\n",
    "    print(f\"Rows with any issues: {summary['n_rows_with_issues']}\")\n",
    "    print(\"\\nRows by condition:\")\n",
    "    for c in CONDITIONS:\n",
    "        print(f\"  {c}: {summary['rows_by_condition'][c]}\")\n",
    "    print(\"\\nUnique pairs by condition:\")\n",
    "    for c in CONDITIONS:\n",
    "        print(f\"  {c}: {summary['unique_pairs_by_condition'][c]}\")\n",
    "    print(\"\\nPair overlap (should usually be 0 across conditions):\")\n",
    "    print(f\"  full ∩ central: {summary['pair_overlap_full_central']}\")\n",
    "    print(f\"  full ∩ peripheral: {summary['pair_overlap_full_peripheral']}\")\n",
    "    print(f\"  central ∩ peripheral: {summary['pair_overlap_central_peripheral']}\")\n",
    "    print(f\"  all three: {summary['pair_overlap_all_three']}\")\n",
    "\n",
    "    if summary[\"issues_by_type\"]:\n",
    "        print(\"\\nIssues by type:\")\n",
    "        for k, v in summary[\"issues_by_type\"].items():\n",
    "            print(f\"  {k}: {v}\")\n",
    "    else:\n",
    "        print(\"\\nIssues by type: none ✅\")\n",
    "\n",
    "    print(f\"\\nSaved to: {out_p}\")\n",
    "    print(\"  - sanity_report.json\")\n",
    "    print(\"  - rows_normalized.csv\")\n",
    "    print(\"  - pair_summary.csv\")\n",
    "    print(\"  - pair_id_map.csv\")\n",
    "    if not issues_df.empty:\n",
    "        print(\"  - row_issues.csv\")\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "    return out_p / \"sanity_report.json\"\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    parser = argparse.ArgumentParser(description=\"Sanity check testing.json (schema, fixations, pairs, acc).\")\n",
    "    parser.add_argument(\"--root\", default=\".\", help=\"Root folder to search for testing.json (and images if enabled).\")\n",
    "    parser.add_argument(\"--json\", default=None, help=\"Optional explicit path to testing.json.\")\n",
    "    parser.add_argument(\"--out\", default=\"sanity_check_out\", help=\"Output directory for reports.\")\n",
    "    parser.add_argument(\"--check-images\", action=\"store_true\", help=\"Also verify second_image files exist (slower).\")\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    sanity_check(\n",
    "        root=str(args.root),\n",
    "        json_path=args.json,\n",
    "        out_dir=str(args.out),\n",
    "        check_images=bool(args.check_images),\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f73c543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PDF: /Users/daisybuathatseephol/Documents/three_json_output/plots/FULL_TOP3_BOTTOM3_ONEPAGE_SECOND_IMAGE_OVERLAY.pdf\n"
     ]
    }
   ],
   "source": [
    "# file: scripts/export_top_bottom3_onepage_correct_pairid.py\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import re\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Iterable, List, Optional, Sequence, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from PIL import Image\n",
    "\n",
    "try:\n",
    "    from scipy.ndimage import gaussian_filter  # type: ignore\n",
    "except Exception:  # pragma: no cover\n",
    "    gaussian_filter = None\n",
    "\n",
    "\n",
    "CONDITIONS: Tuple[str, ...] = (\"full\", \"central\", \"peripheral\")\n",
    "IMAGE_EXTS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\")\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PairKey:\n",
    "    a: str\n",
    "    b: str\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        return f\"{self.a}__{self.b}\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrialRow:\n",
    "    condition: str\n",
    "    pair: PairKey\n",
    "    first_image: str\n",
    "    second_image: str\n",
    "    correct: Optional[bool]\n",
    "    raw: Dict[str, Any]\n",
    "\n",
    "\n",
    "def _normalize_image_name(name: Any) -> str:\n",
    "    s = str(name).strip().lower()\n",
    "    s = re.sub(r\"\\.(jpg|jpeg|png|bmp|tif|tiff)$\", \"\", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "def _clean_condition(x: Any) -> Optional[str]:\n",
    "    if x is None:\n",
    "        return None\n",
    "    s = str(x).strip().lower()\n",
    "    return s if s in CONDITIONS else None\n",
    "\n",
    "\n",
    "def _as_bool(x: Any) -> Optional[bool]:\n",
    "    if x is None:\n",
    "        return None\n",
    "    if isinstance(x, bool):\n",
    "        return x\n",
    "    if isinstance(x, (int, np.integer)) and x in (0, 1):\n",
    "        return bool(x)\n",
    "    if isinstance(x, str):\n",
    "        v = str(x).strip().lower()\n",
    "        if v in (\"true\", \"t\", \"yes\", \"y\", \"correct\", \"right\", \"1\"):\n",
    "            return True\n",
    "        if v in (\"false\", \"f\", \"no\", \"n\", \"incorrect\", \"wrong\", \"0\"):\n",
    "            return False\n",
    "    return None\n",
    "\n",
    "\n",
    "def _normalize_answer(x: Any) -> Optional[str]:\n",
    "    if x is None:\n",
    "        return None\n",
    "    s = str(x).strip().lower()\n",
    "    return s or None\n",
    "\n",
    "\n",
    "def _detect_correct(item: Dict[str, Any]) -> Optional[bool]:\n",
    "    for k in (\"acc\", \"correct\", \"is_correct\", \"response_correct\", \"trial_correct\", \"accuracy\"):\n",
    "        if k in item:\n",
    "            b = _as_bool(item.get(k))\n",
    "            if b is not None:\n",
    "                return b\n",
    "    subj = _normalize_answer(item.get(\"subj_answer\"))\n",
    "    corr = _normalize_answer(item.get(\"correct_response\"))\n",
    "    if subj is not None and corr is not None:\n",
    "        return subj == corr\n",
    "    return None\n",
    "\n",
    "\n",
    "def _find_testing_json(root: Path) -> Path:\n",
    "    hits = list(root.rglob(\"testing.json\"))\n",
    "    if not hits:\n",
    "        raise FileNotFoundError(f\"❌ testing.json not found under: {root}\")\n",
    "    hits.sort(key=lambda p: (len(p.parts), str(p)))\n",
    "    return hits[0]\n",
    "\n",
    "\n",
    "def _find_image_file(root: Path, image_name: str) -> Optional[Path]:\n",
    "    base = _normalize_image_name(image_name)\n",
    "    candidates: List[Path] = []\n",
    "    for p in root.rglob(\"*\"):\n",
    "        if not p.is_file():\n",
    "            continue\n",
    "        if p.suffix.lower() not in IMAGE_EXTS:\n",
    "            continue\n",
    "        if _normalize_image_name(p.name) == base or _normalize_image_name(p.stem) == base:\n",
    "            candidates.append(p)\n",
    "    if not candidates:\n",
    "        return None\n",
    "    candidates.sort(key=lambda p: (len(p.parts), str(p)))\n",
    "    return candidates[0]\n",
    "\n",
    "\n",
    "def _iter_trials(data: Sequence[Dict[str, Any]]) -> Iterable[TrialRow]:\n",
    "    for item in data:\n",
    "        cond = _clean_condition(item.get(\"viewing_condition\") or item.get(\"condition\"))\n",
    "        if cond is None:\n",
    "            continue\n",
    "        first = item.get(\"first_image\")\n",
    "        second = item.get(\"second_image\")\n",
    "        if not first or not second:\n",
    "            continue\n",
    "\n",
    "        first_s = str(first).strip()\n",
    "        second_s = str(second).strip()\n",
    "\n",
    "        a = _normalize_image_name(first_s)\n",
    "        b = _normalize_image_name(second_s)\n",
    "        pair = PairKey(*sorted((a, b)))\n",
    "\n",
    "        yield TrialRow(\n",
    "            condition=cond,\n",
    "            pair=pair,\n",
    "            first_image=first_s,\n",
    "            second_image=second_s,\n",
    "            correct=_detect_correct(item),\n",
    "            raw=item,\n",
    "        )\n",
    "\n",
    "\n",
    "def _extract_fixations(item: Dict[str, Any]) -> np.ndarray:\n",
    "    xs = item.get(\"fix_x\")\n",
    "    ys = item.get(\"fix_y\")\n",
    "    if not isinstance(xs, (list, tuple)) or not isinstance(ys, (list, tuple)):\n",
    "        return np.zeros((0, 2), dtype=float)\n",
    "    if len(xs) != len(ys) or len(xs) == 0:\n",
    "        return np.zeros((0, 2), dtype=float)\n",
    "    try:\n",
    "        arr = np.column_stack([np.asarray(xs, dtype=float), np.asarray(ys, dtype=float)])\n",
    "        arr = arr[np.isfinite(arr).all(axis=1)]\n",
    "        return arr\n",
    "    except Exception:\n",
    "        return np.zeros((0, 2), dtype=float)\n",
    "\n",
    "\n",
    "def _screen_dims(item: Dict[str, Any], default: Tuple[int, int]) -> Tuple[int, int]:\n",
    "    for kw, kh in (\n",
    "        (\"screen_width\", \"screen_height\"),\n",
    "        (\"window_width\", \"window_height\"),\n",
    "        (\"display_width\", \"display_height\"),\n",
    "        (\"screenW\", \"screenH\"),\n",
    "    ):\n",
    "        if kw in item and kh in item:\n",
    "            try:\n",
    "                w = int(float(item[kw]))\n",
    "                h = int(float(item[kh]))\n",
    "                if w > 0 and h > 0:\n",
    "                    return w, h\n",
    "            except Exception:\n",
    "                pass\n",
    "    return default\n",
    "\n",
    "\n",
    "def _image_box_extent(screen_w: int, screen_h: int, half_box: int) -> Tuple[int, int, int, int]:\n",
    "    l = screen_w // 2 - half_box\n",
    "    t = screen_h // 2 - half_box\n",
    "    r = screen_w // 2 + half_box\n",
    "    b = screen_h // 2 + half_box\n",
    "    return l, t, r, b\n",
    "\n",
    "\n",
    "def _load_image_resized(path: Path, size_px: int) -> np.ndarray:\n",
    "    img = Image.open(path).convert(\"L\")\n",
    "    img = img.resize((size_px, size_px), resample=Image.BICUBIC)\n",
    "    return np.asarray(img)\n",
    "\n",
    "\n",
    "def _fdm_in_box(\n",
    "    pts: np.ndarray,\n",
    "    l: int,\n",
    "    t: int,\n",
    "    r: int,\n",
    "    b: int,\n",
    "    size_px: int,\n",
    "    sigma: float,\n",
    ") -> np.ndarray:\n",
    "    if len(pts) == 0:\n",
    "        return np.zeros((size_px, size_px), dtype=float)\n",
    "\n",
    "    in_box = (pts[:, 0] >= l) & (pts[:, 0] <= r) & (pts[:, 1] >= t) & (pts[:, 1] <= b)\n",
    "    p = pts[in_box]\n",
    "    if len(p) == 0:\n",
    "        return np.zeros((size_px, size_px), dtype=float)\n",
    "\n",
    "    x = (p[:, 0] - l) / max(1e-9, (r - l)) * (size_px - 1)\n",
    "    y = (p[:, 1] - t) / max(1e-9, (b - t)) * (size_px - 1)\n",
    "    x = np.clip(x, 0, size_px - 1)\n",
    "    y = np.clip(y, 0, size_px - 1)\n",
    "\n",
    "    heat, _, _ = np.histogram2d(y, x, bins=[size_px, size_px], range=[[0, size_px], [0, size_px]])\n",
    "    heat = heat.astype(float)\n",
    "\n",
    "    if gaussian_filter is not None:\n",
    "        heat = gaussian_filter(heat, sigma=sigma)\n",
    "    else:\n",
    "        k = int(max(3, math.ceil(sigma * 3)) * 2 + 1)\n",
    "        ax = np.arange(k) - k // 2\n",
    "        kernel = np.exp(-(ax**2) / (2 * sigma**2))\n",
    "        kernel /= kernel.sum()\n",
    "        heat = np.apply_along_axis(lambda m: np.convolve(m, kernel, mode=\"same\"), axis=0, arr=heat)\n",
    "        heat = np.apply_along_axis(lambda m: np.convolve(m, kernel, mode=\"same\"), axis=1, arr=heat)\n",
    "\n",
    "    s = heat.sum()\n",
    "    if s > 0:\n",
    "        heat /= s\n",
    "    return heat\n",
    "\n",
    "\n",
    "def _aggregate_accuracy(trials: Sequence[TrialRow]) -> pd.DataFrame:\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "    for t in trials:\n",
    "        if t.correct is None:\n",
    "            continue\n",
    "        rows.append({\"condition\": t.condition, \"pair\": t.pair.as_str, \"correct\": int(bool(t.correct))})\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        raise ValueError(\"❌ No correctness detected (acc / subj_answer vs correct_response).\")\n",
    "\n",
    "    return (\n",
    "        df.groupby([\"condition\", \"pair\"], as_index=False)\n",
    "        .agg(N=(\"correct\", \"size\"), right=(\"correct\", \"sum\"))\n",
    "        .assign(wrong=lambda x: x[\"N\"] - x[\"right\"])\n",
    "        .assign(acc=lambda x: x[\"right\"] / x[\"N\"])\n",
    "    )\n",
    "\n",
    "\n",
    "def _build_pair_id_map_from_json_order(trials: Sequence[TrialRow]) -> Dict[str, Dict[str, int]]:\n",
    "    \"\"\"\n",
    "    Pair ID = first time a (condition, pair) appears in testing.json order.\n",
    "    This matches your sanity_check pair_id_map.csv behavior and eliminates '?'\n",
    "    \"\"\"\n",
    "    out: Dict[str, Dict[str, int]] = {c: {} for c in CONDITIONS}\n",
    "    counters = {c: 0 for c in CONDITIONS}\n",
    "    for t in trials:\n",
    "        ps = t.pair.as_str\n",
    "        if ps not in out[t.condition]:\n",
    "            counters[t.condition] += 1\n",
    "            out[t.condition][ps] = counters[t.condition]\n",
    "    return out\n",
    "\n",
    "\n",
    "def _plot_overlay(\n",
    "    ax: plt.Axes,\n",
    "    img_arr: np.ndarray,\n",
    "    pts: np.ndarray,\n",
    "    heat: np.ndarray,\n",
    "    screen_w: int,\n",
    "    screen_h: int,\n",
    "    extent_ltrb: Tuple[int, int, int, int],  # (l,t,r,b)\n",
    "    title1: str,\n",
    "    title2: str,\n",
    "    heatmap_cmap: str,\n",
    "    heatmap_alpha: float,\n",
    "    vmax_mode: str,\n",
    ") -> Any:\n",
    "    l, t, r, b = extent_ltrb\n",
    "    ax.imshow(img_arr, cmap=\"gray\", origin=\"upper\", extent=(l, r, b, t))\n",
    "\n",
    "    if vmax_mode == \"p99\":\n",
    "        vmax = float(np.quantile(heat, 0.99)) if heat.max() > 0 else 1.0\n",
    "    else:\n",
    "        vmax = float(heat.max()) if heat.max() > 0 else 1.0\n",
    "\n",
    "    hm = ax.imshow(\n",
    "        heat,\n",
    "        origin=\"upper\",\n",
    "        extent=(l, r, b, t),\n",
    "        cmap=heatmap_cmap,\n",
    "        alpha=heatmap_alpha,\n",
    "        vmin=0.0,\n",
    "        vmax=vmax,\n",
    "    )\n",
    "\n",
    "    if len(pts) > 0:\n",
    "        ax.scatter(\n",
    "            pts[:, 0],\n",
    "            pts[:, 1],\n",
    "            s=30,\n",
    "            facecolors=(1.0, 0.42, 0.42, 0.50),\n",
    "            edgecolors=(1.0, 1.0, 1.0, 0.80),\n",
    "            linewidths=0.8,\n",
    "        )\n",
    "\n",
    "    ax.set_xlim(0, screen_w)\n",
    "    ax.set_ylim(screen_h, 0)\n",
    "    ax.set_xlabel(\"x (screen px)\")\n",
    "    ax.set_ylabel(\"y (screen px)\")\n",
    "    ax.set_title(f\"{title1}\\n{title2}\", fontsize=10)\n",
    "    ax.grid(False)\n",
    "    return hm\n",
    "\n",
    "\n",
    "def export_one_page_top_bottom3(\n",
    "    root_path: str,\n",
    "    output_dir: str,\n",
    "    condition: str,\n",
    "    half_box: int = 310,\n",
    "    screen_default: Tuple[int, int] = (1000, 800),\n",
    "    sigma: float = 18.0,\n",
    "    heatmap_alpha: float = 0.70,\n",
    "    heatmap_cmap: str = \"turbo\",\n",
    "    vmax_mode: str = \"p99\",\n",
    ") -> Path:\n",
    "    cond = _clean_condition(condition)\n",
    "    if cond is None:\n",
    "        raise ValueError(f\"--condition must be one of {CONDITIONS}\")\n",
    "\n",
    "    root = Path(root_path).expanduser().resolve()\n",
    "    out_dir = Path(output_dir).expanduser().resolve()\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    json_path = _find_testing_json(root)\n",
    "    data = json.loads(json_path.read_text(encoding=\"utf-8\"))\n",
    "    if not isinstance(data, list):\n",
    "        raise ValueError(\"❌ testing.json must be a list of objects.\")\n",
    "\n",
    "    all_trials = list(_iter_trials(data))\n",
    "    pair_id_map = _build_pair_id_map_from_json_order(all_trials)\n",
    "\n",
    "    # Ensure we really have 24 ids for this condition (else fail loudly)\n",
    "    n_ids = len(pair_id_map[cond])\n",
    "    if n_ids != 24:\n",
    "        raise ValueError(\n",
    "            f\"Expected 24 pairs for condition={cond}, but found {n_ids}. \"\n",
    "            f\"If this is intentional, change the check or print pair_id_map[{cond}].\"\n",
    "        )\n",
    "\n",
    "    agg = _aggregate_accuracy(all_trials)\n",
    "    cond_agg = agg[agg[\"condition\"] == cond].copy()\n",
    "    cond_agg = cond_agg.sort_values([\"acc\", \"pair\"], ascending=[True, True]).reset_index(drop=True)\n",
    "    n_pairs = len(cond_agg)\n",
    "\n",
    "    bottom3 = cond_agg.head(3).copy()  # most incorrect -> less incorrect\n",
    "    top3 = cond_agg.tail(3).sort_values([\"acc\", \"pair\"], ascending=[False, True]).copy()  # most correct -> less correct\n",
    "\n",
    "    out_pdf = out_dir / f\"{cond.upper()}_TOP3_BOTTOM3_ONEPAGE_SECOND_IMAGE_OVERLAY.pdf\"\n",
    "\n",
    "    with PdfPages(out_pdf) as pdf:\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 10), constrained_layout=True)\n",
    "        last_hm = None\n",
    "\n",
    "        def render(row_df: pd.DataFrame, row_idx: int, label: str) -> None:\n",
    "            nonlocal last_hm\n",
    "            for j in range(3):\n",
    "                ax = axes[row_idx, j]\n",
    "                if j >= len(row_df):\n",
    "                    ax.axis(\"off\")\n",
    "                    continue\n",
    "\n",
    "                row = row_df.iloc[j]\n",
    "                pair_str = str(row[\"pair\"])\n",
    "                trials = [t for t in all_trials if t.condition == cond and t.pair.as_str == pair_str]\n",
    "                if not trials:\n",
    "                    ax.axis(\"off\")\n",
    "                    continue\n",
    "\n",
    "                img_path = _find_image_file(root, trials[0].second_image)\n",
    "                if img_path is None:\n",
    "                    ax.set_title(\"missing second image\", fontsize=10)\n",
    "                    ax.axis(\"off\")\n",
    "                    continue\n",
    "\n",
    "                sw, sh = screen_default\n",
    "                for t in trials[:3]:\n",
    "                    sw, sh = _screen_dims(t.raw, (sw, sh))\n",
    "\n",
    "                l, ttop, r, b = _image_box_extent(sw, sh, half_box=half_box)\n",
    "                box_size = int(half_box * 2)\n",
    "\n",
    "                img_arr = _load_image_resized(img_path, size_px=box_size)\n",
    "                pts = np.vstack([_extract_fixations(t.raw) for t in trials])\n",
    "                heat = _fdm_in_box(pts, l=l, t=ttop, r=r, b=b, size_px=box_size, sigma=sigma)\n",
    "\n",
    "                acc = float(row[\"acc\"])\n",
    "                right = int(row[\"right\"])\n",
    "                wrong = int(row[\"wrong\"])\n",
    "                N = int(row[\"N\"])\n",
    "\n",
    "                pair_id = pair_id_map[cond].get(pair_str)\n",
    "                if pair_id is None:\n",
    "                    raise RuntimeError(f\"Pair ID missing for condition={cond} pair={pair_str}\")\n",
    "\n",
    "                correctness_label = \"Correct\" if acc >= 0.5 else \"Incorrect\"\n",
    "                title1 = f\"Testing • Acc: {acc*100:.1f}% • Pair {pair_id}/{n_pairs} • {correctness_label}\"\n",
    "                title2 = f\"Subjects: right={right} • wrong={wrong} • N={N} subjects • Second: {len(pts)} fix\"\n",
    "\n",
    "                last_hm = _plot_overlay(\n",
    "                    ax=ax,\n",
    "                    img_arr=img_arr,\n",
    "                    pts=pts,\n",
    "                    heat=heat,\n",
    "                    screen_w=sw,\n",
    "                    screen_h=sh,\n",
    "                    extent_ltrb=(l, ttop, r, b),\n",
    "                    title1=title1,\n",
    "                    title2=title2,\n",
    "                    heatmap_cmap=heatmap_cmap,\n",
    "                    heatmap_alpha=heatmap_alpha,\n",
    "                    vmax_mode=vmax_mode,\n",
    "                )\n",
    "\n",
    "                ax.text(\n",
    "                    0.01,\n",
    "                    0.99,\n",
    "                    label,\n",
    "                    transform=ax.transAxes,\n",
    "                    va=\"top\",\n",
    "                    ha=\"left\",\n",
    "                    fontsize=10,\n",
    "                    fontweight=\"bold\",\n",
    "                    bbox=dict(boxstyle=\"round,pad=0.2\", fc=\"white\", ec=\"none\", alpha=0.7),\n",
    "                )\n",
    "\n",
    "        render(top3.reset_index(drop=True), row_idx=0, label=\"TOP 3\")\n",
    "        render(bottom3.reset_index(drop=True), row_idx=1, label=\"BOTTOM 3\")\n",
    "\n",
    "        fig.suptitle(\n",
    "            f\"Testing Phase - {cond.upper()} Viewing Condition\\n\"\n",
    "            f\"Top 3 (High Accuracy) + Bottom 3 (Low Accuracy)\\n\"\n",
    "            f\"Top: Most Correct \\u2192 Least Correct   |   Bottom: Most Incorrect \\u2192 Least Incorrect\",\n",
    "            fontsize=14,\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "\n",
    "        if last_hm is not None:\n",
    "            cbar = fig.colorbar(last_hm, ax=axes.ravel().tolist(), shrink=0.85, pad=0.02)\n",
    "            cbar.set_label(\"Fixation Density\", rotation=90)\n",
    "\n",
    "        pdf.savefig(fig)\n",
    "        plt.close(fig)\n",
    "\n",
    "    return out_pdf\n",
    "\n",
    "\n",
    "def _running_in_notebook(argv: List[str]) -> bool:\n",
    "    return \"-f\" in argv or \"ipykernel\" in argv[0].lower()\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"One PDF, one page: Top 3 + Bottom 3 for ONE viewing condition with correct Pair IDs (no '?').\"\n",
    "    )\n",
    "    parser.add_argument(\"--root\", default=\".\", help=\"Folder to search for testing.json and images.\")\n",
    "    parser.add_argument(\"--out\", default=\"plots\", help=\"Output directory.\")\n",
    "    parser.add_argument(\"--condition\", default=\"full\", choices=list(CONDITIONS))\n",
    "    parser.add_argument(\"--half-box\", type=int, default=310)\n",
    "    parser.add_argument(\"--screen-w\", type=int, default=1000)\n",
    "    parser.add_argument(\"--screen-h\", type=int, default=800)\n",
    "    parser.add_argument(\"--sigma\", type=float, default=18.0)\n",
    "    parser.add_argument(\"--heatmap-alpha\", type=float, default=0.70)\n",
    "    parser.add_argument(\"--heatmap-cmap\", default=\"turbo\")\n",
    "    parser.add_argument(\"--vmax-mode\", default=\"p99\", choices=[\"p99\", \"max\"])\n",
    "\n",
    "    argv = sys.argv[1:]\n",
    "    if _running_in_notebook(sys.argv):\n",
    "        args = parser.parse_args([])  # ignore Jupyter argv\n",
    "    else:\n",
    "        args, _unknown = parser.parse_known_args(argv)\n",
    "\n",
    "    out_pdf = export_one_page_top_bottom3(\n",
    "        root_path=args.root,\n",
    "        output_dir=args.out,\n",
    "        condition=str(args.condition),\n",
    "        half_box=int(args.half_box),\n",
    "        screen_default=(int(args.screen_w), int(args.screen_h)),\n",
    "        sigma=float(args.sigma),\n",
    "        heatmap_alpha=float(args.heatmap_alpha),\n",
    "        heatmap_cmap=str(args.heatmap_cmap),\n",
    "        vmax_mode=str(args.vmax_mode),\n",
    "    )\n",
    "    print(f\"✅ PDF: {out_pdf}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "002b750b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PDF: /Users/daisybuathatseephol/Documents/three_json_output/plots/FULL_TOP3_BOTTOM3_ONEPAGE_SECOND_IMAGE_OVERLAY.pdf\n",
      "✅ PDF: /Users/daisybuathatseephol/Documents/three_json_output/plots/CENTRAL_TOP3_BOTTOM3_ONEPAGE_SECOND_IMAGE_OVERLAY.pdf\n",
      "✅ PDF: /Users/daisybuathatseephol/Documents/three_json_output/plots/PERIPHERAL_TOP3_BOTTOM3_ONEPAGE_SECOND_IMAGE_OVERLAY.pdf\n"
     ]
    }
   ],
   "source": [
    "# file: scripts/export_top_bottom3_onepage_correct_pairid.py\n",
    "\"\"\"\n",
    "Export fixation+FDM overlays for Top 3 (highest accuracy) and Bottom 3 (lowest accuracy)\n",
    "pairs within a viewing condition, using the *correct* Pair ID (1..24) derived from\n",
    "first appearance order in testing.json for that condition.\n",
    "\n",
    "Outputs:\n",
    "- If --condition full|central|peripheral: one PDF (one page, 2x3 grid)\n",
    "- If --condition all: three PDFs (one per condition)\n",
    "\n",
    "Example:\n",
    "  python scripts/export_top_bottom3_onepage_correct_pairid.py \\\n",
    "    --root /path/to/three_json_output --out plots --condition all\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import re\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Iterable, List, Optional, Sequence, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from PIL import Image\n",
    "\n",
    "try:\n",
    "    from scipy.ndimage import gaussian_filter  # type: ignore\n",
    "except Exception:  # pragma: no cover\n",
    "    gaussian_filter = None\n",
    "\n",
    "\n",
    "CONDITIONS: Tuple[str, ...] = (\"full\", \"central\", \"peripheral\")\n",
    "IMAGE_EXTS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\")\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PairKey:\n",
    "    a: str\n",
    "    b: str\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        return f\"{self.a}__{self.b}\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrialRow:\n",
    "    condition: str\n",
    "    pair: PairKey\n",
    "    first_image: str\n",
    "    second_image: str\n",
    "    correct: Optional[bool]\n",
    "    raw: Dict[str, Any]\n",
    "\n",
    "\n",
    "def _normalize_image_name(name: Any) -> str:\n",
    "    s = str(name).strip().lower()\n",
    "    s = re.sub(r\"\\.(jpg|jpeg|png|bmp|tif|tiff)$\", \"\", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "def _clean_condition(x: Any) -> Optional[str]:\n",
    "    if x is None:\n",
    "        return None\n",
    "    s = str(x).strip().lower()\n",
    "    return s if s in CONDITIONS else None\n",
    "\n",
    "\n",
    "def _as_bool(x: Any) -> Optional[bool]:\n",
    "    if x is None:\n",
    "        return None\n",
    "    if isinstance(x, bool):\n",
    "        return x\n",
    "    if isinstance(x, (int, np.integer)) and x in (0, 1):\n",
    "        return bool(x)\n",
    "    if isinstance(x, str):\n",
    "        v = str(x).strip().lower()\n",
    "        if v in (\"true\", \"t\", \"yes\", \"y\", \"correct\", \"right\", \"1\"):\n",
    "            return True\n",
    "        if v in (\"false\", \"f\", \"no\", \"n\", \"incorrect\", \"wrong\", \"0\"):\n",
    "            return False\n",
    "    return None\n",
    "\n",
    "\n",
    "def _normalize_answer(x: Any) -> Optional[str]:\n",
    "    if x is None:\n",
    "        return None\n",
    "    s = str(x).strip().lower()\n",
    "    return s or None\n",
    "\n",
    "\n",
    "def _detect_correct(item: Dict[str, Any]) -> Optional[bool]:\n",
    "    for k in (\"acc\", \"correct\", \"is_correct\", \"response_correct\", \"trial_correct\", \"accuracy\"):\n",
    "        if k in item:\n",
    "            b = _as_bool(item.get(k))\n",
    "            if b is not None:\n",
    "                return b\n",
    "    subj = _normalize_answer(item.get(\"subj_answer\"))\n",
    "    corr = _normalize_answer(item.get(\"correct_response\"))\n",
    "    if subj is not None and corr is not None:\n",
    "        return subj == corr\n",
    "    return None\n",
    "\n",
    "\n",
    "def _find_testing_json(root: Path) -> Path:\n",
    "    hits = list(root.rglob(\"testing.json\"))\n",
    "    if not hits:\n",
    "        raise FileNotFoundError(f\"❌ testing.json not found under: {root}\")\n",
    "    hits.sort(key=lambda p: (len(p.parts), str(p)))\n",
    "    return hits[0]\n",
    "\n",
    "\n",
    "def _find_image_file(root: Path, image_name: str) -> Optional[Path]:\n",
    "    base = _normalize_image_name(image_name)\n",
    "    candidates: List[Path] = []\n",
    "    for p in root.rglob(\"*\"):\n",
    "        if not p.is_file():\n",
    "            continue\n",
    "        if p.suffix.lower() not in IMAGE_EXTS:\n",
    "            continue\n",
    "        if _normalize_image_name(p.name) == base or _normalize_image_name(p.stem) == base:\n",
    "            candidates.append(p)\n",
    "    if not candidates:\n",
    "        return None\n",
    "    candidates.sort(key=lambda p: (len(p.parts), str(p)))\n",
    "    return candidates[0]\n",
    "\n",
    "\n",
    "def _iter_trials(data: Sequence[Dict[str, Any]]) -> Iterable[TrialRow]:\n",
    "    for item in data:\n",
    "        cond = _clean_condition(item.get(\"viewing_condition\") or item.get(\"condition\"))\n",
    "        if cond is None:\n",
    "            continue\n",
    "\n",
    "        first = item.get(\"first_image\")\n",
    "        second = item.get(\"second_image\")\n",
    "        if not first or not second:\n",
    "            continue\n",
    "\n",
    "        first_s = str(first).strip()\n",
    "        second_s = str(second).strip()\n",
    "\n",
    "        a = _normalize_image_name(first_s)\n",
    "        b = _normalize_image_name(second_s)\n",
    "        pair = PairKey(*sorted((a, b)))\n",
    "\n",
    "        yield TrialRow(\n",
    "            condition=cond,\n",
    "            pair=pair,\n",
    "            first_image=first_s,\n",
    "            second_image=second_s,\n",
    "            correct=_detect_correct(item),\n",
    "            raw=item,\n",
    "        )\n",
    "\n",
    "\n",
    "def _extract_fixations(item: Dict[str, Any]) -> np.ndarray:\n",
    "    xs = item.get(\"fix_x\")\n",
    "    ys = item.get(\"fix_y\")\n",
    "    if not isinstance(xs, (list, tuple)) or not isinstance(ys, (list, tuple)):\n",
    "        return np.zeros((0, 2), dtype=float)\n",
    "    if len(xs) != len(ys) or len(xs) == 0:\n",
    "        return np.zeros((0, 2), dtype=float)\n",
    "    try:\n",
    "        arr = np.column_stack([np.asarray(xs, dtype=float), np.asarray(ys, dtype=float)])\n",
    "        arr = arr[np.isfinite(arr).all(axis=1)]\n",
    "        return arr\n",
    "    except Exception:\n",
    "        return np.zeros((0, 2), dtype=float)\n",
    "\n",
    "\n",
    "def _screen_dims(item: Dict[str, Any], default: Tuple[int, int]) -> Tuple[int, int]:\n",
    "    for kw, kh in (\n",
    "        (\"screen_width\", \"screen_height\"),\n",
    "        (\"window_width\", \"window_height\"),\n",
    "        (\"display_width\", \"display_height\"),\n",
    "        (\"screenW\", \"screenH\"),\n",
    "    ):\n",
    "        if kw in item and kh in item:\n",
    "            try:\n",
    "                w = int(float(item[kw]))\n",
    "                h = int(float(item[kh]))\n",
    "                if w > 0 and h > 0:\n",
    "                    return w, h\n",
    "            except Exception:\n",
    "                pass\n",
    "    return default\n",
    "\n",
    "\n",
    "def _image_box_extent(screen_w: int, screen_h: int, half_box: int) -> Tuple[int, int, int, int]:\n",
    "    l = screen_w // 2 - half_box\n",
    "    t = screen_h // 2 - half_box\n",
    "    r = screen_w // 2 + half_box\n",
    "    b = screen_h // 2 + half_box\n",
    "    return l, t, r, b\n",
    "\n",
    "\n",
    "def _load_image_resized(path: Path, size_px: int) -> np.ndarray:\n",
    "    img = Image.open(path).convert(\"L\")\n",
    "    img = img.resize((size_px, size_px), resample=Image.BICUBIC)\n",
    "    return np.asarray(img)\n",
    "\n",
    "\n",
    "def _fdm_in_box(\n",
    "    pts: np.ndarray,\n",
    "    l: int,\n",
    "    t: int,\n",
    "    r: int,\n",
    "    b: int,\n",
    "    size_px: int,\n",
    "    sigma: float,\n",
    ") -> np.ndarray:\n",
    "    if len(pts) == 0:\n",
    "        return np.zeros((size_px, size_px), dtype=float)\n",
    "\n",
    "    in_box = (pts[:, 0] >= l) & (pts[:, 0] <= r) & (pts[:, 1] >= t) & (pts[:, 1] <= b)\n",
    "    p = pts[in_box]\n",
    "    if len(p) == 0:\n",
    "        return np.zeros((size_px, size_px), dtype=float)\n",
    "\n",
    "    x = (p[:, 0] - l) / max(1e-9, (r - l)) * (size_px - 1)\n",
    "    y = (p[:, 1] - t) / max(1e-9, (b - t)) * (size_px - 1)\n",
    "    x = np.clip(x, 0, size_px - 1)\n",
    "    y = np.clip(y, 0, size_px - 1)\n",
    "\n",
    "    heat, _, _ = np.histogram2d(y, x, bins=[size_px, size_px], range=[[0, size_px], [0, size_px]])\n",
    "    heat = heat.astype(float)\n",
    "\n",
    "    if gaussian_filter is not None:\n",
    "        heat = gaussian_filter(heat, sigma=sigma)\n",
    "    else:\n",
    "        k = int(max(3, math.ceil(sigma * 3)) * 2 + 1)\n",
    "        ax = np.arange(k) - k // 2\n",
    "        kernel = np.exp(-(ax**2) / (2 * sigma**2))\n",
    "        kernel /= kernel.sum()\n",
    "        heat = np.apply_along_axis(lambda m: np.convolve(m, kernel, mode=\"same\"), axis=0, arr=heat)\n",
    "        heat = np.apply_along_axis(lambda m: np.convolve(m, kernel, mode=\"same\"), axis=1, arr=heat)\n",
    "\n",
    "    s = heat.sum()\n",
    "    if s > 0:\n",
    "        heat /= s\n",
    "    return heat\n",
    "\n",
    "\n",
    "def _aggregate_accuracy(trials: Sequence[TrialRow]) -> pd.DataFrame:\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "    for t in trials:\n",
    "        if t.correct is None:\n",
    "            continue\n",
    "        rows.append({\"condition\": t.condition, \"pair\": t.pair.as_str, \"correct\": int(bool(t.correct))})\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        raise ValueError(\"❌ No correctness detected (acc / subj_answer vs correct_response).\")\n",
    "\n",
    "    return (\n",
    "        df.groupby([\"condition\", \"pair\"], as_index=False)\n",
    "        .agg(N=(\"correct\", \"size\"), right=(\"correct\", \"sum\"))\n",
    "        .assign(wrong=lambda x: x[\"N\"] - x[\"right\"])\n",
    "        .assign(acc=lambda x: x[\"right\"] / x[\"N\"])\n",
    "    )\n",
    "\n",
    "\n",
    "def _build_pair_id_map_from_json_order(trials: Sequence[TrialRow]) -> Dict[str, Dict[str, int]]:\n",
    "    out: Dict[str, Dict[str, int]] = {c: {} for c in CONDITIONS}\n",
    "    counters = {c: 0 for c in CONDITIONS}\n",
    "    for t in trials:\n",
    "        ps = t.pair.as_str\n",
    "        if ps not in out[t.condition]:\n",
    "            counters[t.condition] += 1\n",
    "            out[t.condition][ps] = counters[t.condition]\n",
    "    return out\n",
    "\n",
    "\n",
    "def _plot_overlay(\n",
    "    ax: plt.Axes,\n",
    "    img_arr: np.ndarray,\n",
    "    pts: np.ndarray,\n",
    "    heat: np.ndarray,\n",
    "    screen_w: int,\n",
    "    screen_h: int,\n",
    "    extent_ltrb: Tuple[int, int, int, int],  # (l,t,r,b)\n",
    "    title1: str,\n",
    "    title2: str,\n",
    "    heatmap_cmap: str,\n",
    "    heatmap_alpha: float,\n",
    "    vmax_mode: str,\n",
    "):\n",
    "    l, t, r, b = extent_ltrb\n",
    "    ax.imshow(img_arr, cmap=\"gray\", origin=\"upper\", extent=(l, r, b, t))\n",
    "\n",
    "    if vmax_mode == \"p99\":\n",
    "        vmax = float(np.quantile(heat, 0.99)) if heat.max() > 0 else 1.0\n",
    "    else:\n",
    "        vmax = float(heat.max()) if heat.max() > 0 else 1.0\n",
    "\n",
    "    hm = ax.imshow(\n",
    "        heat,\n",
    "        origin=\"upper\",\n",
    "        extent=(l, r, b, t),\n",
    "        cmap=heatmap_cmap,\n",
    "        alpha=heatmap_alpha,\n",
    "        vmin=0.0,\n",
    "        vmax=vmax,\n",
    "    )\n",
    "\n",
    "    if len(pts) > 0:\n",
    "        ax.scatter(\n",
    "            pts[:, 0],\n",
    "            pts[:, 1],\n",
    "            s=30,\n",
    "            facecolors=(1.0, 0.42, 0.42, 0.50),\n",
    "            edgecolors=(1.0, 1.0, 1.0, 0.80),\n",
    "            linewidths=0.8,\n",
    "        )\n",
    "\n",
    "    ax.set_xlim(0, screen_w)\n",
    "    ax.set_ylim(screen_h, 0)\n",
    "    ax.set_xlabel(\"x (screen px)\")\n",
    "    ax.set_ylabel(\"y (screen px)\")\n",
    "    ax.set_title(f\"{title1}\\n{title2}\", fontsize=10)\n",
    "    ax.grid(False)\n",
    "    return hm\n",
    "\n",
    "\n",
    "def export_one_page_top_bottom3(\n",
    "    root_path: str,\n",
    "    output_dir: str,\n",
    "    condition: str,\n",
    "    half_box: int = 310,\n",
    "    screen_default: Tuple[int, int] = (1000, 800),\n",
    "    sigma: float = 18.0,\n",
    "    heatmap_alpha: float = 0.70,\n",
    "    heatmap_cmap: str = \"turbo\",\n",
    "    vmax_mode: str = \"p99\",\n",
    "    expected_pairs: int = 24,\n",
    ") -> Path:\n",
    "    cond = _clean_condition(condition)\n",
    "    if cond is None:\n",
    "        raise ValueError(f\"--condition must be one of {CONDITIONS}\")\n",
    "\n",
    "    root = Path(root_path).expanduser().resolve()\n",
    "    out_dir = Path(output_dir).expanduser().resolve()\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    json_path = _find_testing_json(root)\n",
    "    data = json.loads(json_path.read_text(encoding=\"utf-8\"))\n",
    "    if not isinstance(data, list):\n",
    "        raise ValueError(\"❌ testing.json must be a list of objects.\")\n",
    "\n",
    "    all_trials = list(_iter_trials(data))\n",
    "    pair_id_map = _build_pair_id_map_from_json_order(all_trials)\n",
    "\n",
    "    n_ids = len(pair_id_map[cond])\n",
    "    if expected_pairs and n_ids != expected_pairs:\n",
    "        raise ValueError(f\"Expected {expected_pairs} pairs for {cond}, found {n_ids}.\")\n",
    "\n",
    "    agg = _aggregate_accuracy(all_trials)\n",
    "    cond_agg = agg[agg[\"condition\"] == cond].copy()\n",
    "    cond_agg = cond_agg.sort_values([\"acc\", \"pair\"], ascending=[True, True]).reset_index(drop=True)\n",
    "    n_pairs = len(cond_agg)\n",
    "\n",
    "    bottom3 = cond_agg.head(3).copy()\n",
    "    top3 = cond_agg.tail(3).sort_values([\"acc\", \"pair\"], ascending=[False, True]).copy()\n",
    "\n",
    "    out_pdf = out_dir / f\"{cond.upper()}_TOP3_BOTTOM3_ONEPAGE_SECOND_IMAGE_OVERLAY.pdf\"\n",
    "\n",
    "    with PdfPages(out_pdf) as pdf:\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 10), constrained_layout=True)\n",
    "        last_hm = None\n",
    "\n",
    "        def render(row_df: pd.DataFrame, row_idx: int, label: str) -> None:\n",
    "            nonlocal last_hm\n",
    "            for j in range(3):\n",
    "                ax = axes[row_idx, j]\n",
    "                if j >= len(row_df):\n",
    "                    ax.axis(\"off\")\n",
    "                    continue\n",
    "\n",
    "                row = row_df.iloc[j]\n",
    "                pair_str = str(row[\"pair\"])\n",
    "                trials = [t for t in all_trials if t.condition == cond and t.pair.as_str == pair_str]\n",
    "                if not trials:\n",
    "                    ax.axis(\"off\")\n",
    "                    continue\n",
    "\n",
    "                img_path = _find_image_file(root, trials[0].second_image)\n",
    "                if img_path is None:\n",
    "                    ax.set_title(\"missing second image\", fontsize=10)\n",
    "                    ax.axis(\"off\")\n",
    "                    continue\n",
    "\n",
    "                sw, sh = screen_default\n",
    "                for tr in trials[:3]:\n",
    "                    sw, sh = _screen_dims(tr.raw, (sw, sh))\n",
    "\n",
    "                l, ttop, r, b = _image_box_extent(sw, sh, half_box=half_box)\n",
    "                box_size = int(half_box * 2)\n",
    "\n",
    "                img_arr = _load_image_resized(img_path, size_px=box_size)\n",
    "                pts = np.vstack([_extract_fixations(tr.raw) for tr in trials])\n",
    "                heat = _fdm_in_box(pts, l=l, t=ttop, r=r, b=b, size_px=box_size, sigma=sigma)\n",
    "\n",
    "                acc = float(row[\"acc\"])\n",
    "                right = int(row[\"right\"])\n",
    "                wrong = int(row[\"wrong\"])\n",
    "                N = int(row[\"N\"])\n",
    "\n",
    "                pair_id = pair_id_map[cond].get(pair_str)\n",
    "                if pair_id is None:\n",
    "                    raise RuntimeError(f\"Pair ID missing for condition={cond} pair={pair_str}\")\n",
    "\n",
    "                correctness_label = \"Correct\" if acc >= 0.5 else \"Incorrect\"\n",
    "                title1 = f\"Testing • Acc: {acc*100:.1f}% • Pair {pair_id}/{n_pairs} • {correctness_label}\"\n",
    "                title2 = f\"Subjects: right={right} • wrong={wrong} • N={N} subjects • Second: {len(pts)} fix\"\n",
    "\n",
    "                last_hm = _plot_overlay(\n",
    "                    ax=ax,\n",
    "                    img_arr=img_arr,\n",
    "                    pts=pts,\n",
    "                    heat=heat,\n",
    "                    screen_w=sw,\n",
    "                    screen_h=sh,\n",
    "                    extent_ltrb=(l, ttop, r, b),\n",
    "                    title1=title1,\n",
    "                    title2=title2,\n",
    "                    heatmap_cmap=heatmap_cmap,\n",
    "                    heatmap_alpha=heatmap_alpha,\n",
    "                    vmax_mode=vmax_mode,\n",
    "                )\n",
    "\n",
    "                ax.text(\n",
    "                    0.01,\n",
    "                    0.99,\n",
    "                    label,\n",
    "                    transform=ax.transAxes,\n",
    "                    va=\"top\",\n",
    "                    ha=\"left\",\n",
    "                    fontsize=10,\n",
    "                    fontweight=\"bold\",\n",
    "                    bbox=dict(boxstyle=\"round,pad=0.2\", fc=\"white\", ec=\"none\", alpha=0.7),\n",
    "                )\n",
    "\n",
    "        render(top3.reset_index(drop=True), row_idx=0, label=\"TOP 3\")\n",
    "        render(bottom3.reset_index(drop=True), row_idx=1, label=\"BOTTOM 3\")\n",
    "\n",
    "        fig.suptitle(\n",
    "            f\"Testing Phase - {cond.upper()} Viewing Condition\\n\"\n",
    "            f\"Top 3 (High Accuracy) + Bottom 3 (Low Accuracy)\\n\"\n",
    "            f\"Top: Most Correct \\u2192 Least Correct   |   Bottom: Most Incorrect \\u2192 Least Incorrect\",\n",
    "            fontsize=14,\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "\n",
    "        if last_hm is not None:\n",
    "            cbar = fig.colorbar(last_hm, ax=axes.ravel().tolist(), shrink=0.85, pad=0.02)\n",
    "            cbar.set_label(\"Fixation Density\", rotation=90)\n",
    "\n",
    "        pdf.savefig(fig)\n",
    "        plt.close(fig)\n",
    "\n",
    "    return out_pdf\n",
    "\n",
    "\n",
    "def _running_in_notebook(argv: List[str]) -> bool:\n",
    "    return \"-f\" in argv or \"ipykernel\" in argv[0].lower()\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"One PDF, one page: Top 3 + Bottom 3 for one or all viewing conditions (correct Pair IDs).\"\n",
    "    )\n",
    "    parser.add_argument(\"--root\", default=\".\", help=\"Folder to search for testing.json and images.\")\n",
    "    parser.add_argument(\"--out\", default=\"plots\", help=\"Output directory.\")\n",
    "    parser.add_argument(\n",
    "        \"--condition\",\n",
    "        default=\"all\",\n",
    "        choices=[\"all\", \"full\", \"central\", \"peripheral\"],\n",
    "        help=\"Which condition to export (or all).\",\n",
    "    )\n",
    "    parser.add_argument(\"--half-box\", type=int, default=310)\n",
    "    parser.add_argument(\"--screen-w\", type=int, default=1000)\n",
    "    parser.add_argument(\"--screen-h\", type=int, default=800)\n",
    "    parser.add_argument(\"--sigma\", type=float, default=18.0)\n",
    "    parser.add_argument(\"--heatmap-alpha\", type=float, default=0.70)\n",
    "    parser.add_argument(\"--heatmap-cmap\", default=\"turbo\")\n",
    "    parser.add_argument(\"--vmax-mode\", default=\"p99\", choices=[\"p99\", \"max\"])\n",
    "    parser.add_argument(\"--expected-pairs\", type=int, default=24)\n",
    "\n",
    "    argv = sys.argv[1:]\n",
    "    if _running_in_notebook(sys.argv):\n",
    "        args = parser.parse_args([])\n",
    "    else:\n",
    "        args, _unknown = parser.parse_known_args(argv)\n",
    "\n",
    "    conditions = list(CONDITIONS) if args.condition == \"all\" else [str(args.condition)]\n",
    "\n",
    "    for cond in conditions:\n",
    "        out_pdf = export_one_page_top_bottom3(\n",
    "            root_path=str(args.root),\n",
    "            output_dir=str(args.out),\n",
    "            condition=cond,\n",
    "            half_box=int(args.half_box),\n",
    "            screen_default=(int(args.screen_w), int(args.screen_h)),\n",
    "            sigma=float(args.sigma),\n",
    "            heatmap_alpha=float(args.heatmap_alpha),\n",
    "            heatmap_cmap=str(args.heatmap_cmap),\n",
    "            vmax_mode=str(args.vmax_mode),\n",
    "            expected_pairs=int(args.expected_pairs),\n",
    "        )\n",
    "        print(f\"✅ PDF: {out_pdf}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birdgaze",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
